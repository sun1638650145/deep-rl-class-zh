{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3c747ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ç¬¬5å•å…ƒ: ä½¿ç”¨PyTorchç¼–å†™ä½ çš„ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•: Reinforce. å¹¶æµ‹è¯•å®ƒçš„é²æ£’æ€§ ğŸ’ª\n",
    "\n",
    "åœ¨è¿™ä»½ç¬”è®°ä¸­, ä½ å°†ä»å¤´ç¼–å†™ä½ çš„ç¬¬ä¸€ä¸ªæ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•: Reinforce(ä¹Ÿç§°ä¸ºè’™ç‰¹å¡æ´›ç­–ç•¥æ¢¯åº¦).\n",
    "\n",
    "Reinforceæ˜¯ä¸€ç§**åŸºäºç­–ç•¥çš„æ–¹æ³•**: ä¸€ç§**å°è¯•ç›´æ¥ä¼˜åŒ–ç­–ç•¥è€Œä¸æ˜¯ä½¿ç”¨åŠ¨ä½œä»·å€¼å‡½æ•°**çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•. æ›´å‡†ç¡®çš„è¯´, Reinforceæ˜¯ç­–ç•¥æ¢¯åº¦æ–¹æ³•, æ˜¯åŸºäºç­–ç•¥æ–¹æ³•çš„å­ç±», æ—¨åœ¨**é€šè¿‡ä½¿ç”¨æ¢¯åº¦æå‡(Gradient Ascent)ä¼°è®¡æœ€ä¼˜ç­–ç•¥çš„æƒé‡æ¥ç›´æ¥ä¼˜åŒ–ç­–ç•¥.**\n",
    "\n",
    "ä¸ºäº†æµ‹è¯•é²æ£’æ€§, æˆ‘ä»¬å°†åœ¨3ä¸ªä¸åŒçš„ç®€å•ç¯å¢ƒè¿›è¡Œè®­ç»ƒ:\n",
    "* Cartpole-v1\n",
    "* PixelCopterEnv\n",
    "* PongEnv\n",
    "\n",
    "â“å¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜, è¯·åœ¨discordçš„#study-group-unit5é¢‘é“å‘å¸– ğŸ‘‰ https://discord.gg/aYka4Yhff9\n",
    "\n",
    "ğŸ® ç¯å¢ƒ:\n",
    "\n",
    "* [CartPole-v1](https://www.gymlibrary.ml/environments/classic_control/cart_pole/)\n",
    "* [PixelCopter](https://pygame-learning-environment.readthedocs.io/en/latest/user/games/pixelcopter.html)\n",
    "* [Pong](https://pygame-learning-environment.readthedocs.io/en/latest/user/games/pong.html)\n",
    "\n",
    "â¬‡ï¸ è¿™æ˜¯**ä½ å°†åœ¨å‡ åˆ†é’Ÿå†…å®ç°çš„ç›®æ ‡**çš„ç¤ºä¾‹. â¬‡ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870bdfa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![Sans titre.gif](./assets/Sans%20titre.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a640e4e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## è¿™ä»½ç¬”è®°çš„ç›®æ ‡ğŸ†\n",
    "\n",
    "åœ¨è¿™ä»½ç¬”è®°å­¦ä¹ ç»“æŸå, ä½ å°†:\n",
    "\n",
    "* èƒ½å¤Ÿä½¿ç”¨**PyTorchä»å¤´ç¼–å†™Reinforceç®—æ³•.**\n",
    "* èƒ½å¤Ÿä½¿ç”¨**ç®€å•çš„ç¯å¢ƒæµ‹è¯•ä½ çš„æ™ºèƒ½ä½“çš„é²æ£’æ€§.**\n",
    "* èƒ½å¤Ÿé€šè¿‡ç²¾å½©çš„å›æ”¾å’Œå¾—åˆ†ğŸ”¥**å‘å¸ƒä½ è®­ç»ƒçš„æ™ºèƒ½ä½“åˆ°Hugging Face Hub.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77934d83",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## è¿™ä»½ç¬”è®°æ¥è‡ªæ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹\n",
    "![Deep Reinforcement Learning Course.jpg](./assets/DeepReinforcementLearningCourse.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5c62e4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "åœ¨è¿™ä¸ªå…è´¹è¯¾ç¨‹ä¸­, ä½ å°†:\n",
    "\n",
    "* ğŸ“– ç ”ç©¶æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„**ç†è®ºå’Œå®è·µ.**\n",
    "* ğŸ§‘â€ğŸ’» å­¦ä¹ **ä½¿ç”¨æµè¡Œçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ åº“**, ä¾‹å¦‚Stable Baselines3, RL Baselines3 Zooå’ŒRLlib.\n",
    "* ğŸ¤–ï¸ **åœ¨ç‹¬ç‰¹çš„ç¯å¢ƒä¸­è®­ç»ƒæ™ºèƒ½ä½“.**\n",
    "\n",
    "è¿˜æœ‰æ›´å¤šçš„è¯¾ç¨‹ ğŸ“š å†…å®¹ ğŸ‘‰ https://github.com/huggingface/deep-rl-class\n",
    "\n",
    "ä¿æŒè¿›åº¦çš„æœ€ä½³æ–¹å¼æ˜¯åŠ å…¥æˆ‘ä»¬çš„DiscordæœåŠ¡å™¨ä¸ç¤¾åŒºå’Œæˆ‘ä»¬è¿›è¡Œäº¤æµ. ğŸ‘‰ğŸ» https://discord.gg/aYka4Yhff9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ddb776",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## å…ˆå†³æ¡ä»¶ ğŸ—\n",
    "\n",
    "åœ¨æ·±å…¥ç ”ç©¶ç¬”è®°ä¹‹å‰, ä½ éœ€è¦:\n",
    "\n",
    "ğŸ”² ğŸ“š [é˜…è¯»ç¬¬5å•å…ƒçš„README.](https://github.com/huggingface/deep-rl-class/blob/main/unit5/README.md)\n",
    "\n",
    "ğŸ”² ğŸ“š é€šè¿‡é˜…è¯» ğŸ‘‰ https://huggingface.co/blog/deep-rl-pg **å­¦ä¹ ç­–ç•¥æ¢¯åº¦**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2882fa6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç¬¬0æ­¥: è®¾ç½®GPU ğŸ’ª\n",
    "\n",
    "* ä¸ºäº†**æ›´å¿«çš„è®­ç»ƒæ™ºèƒ½ä½“, æˆ‘ä»¬å°†ä½¿ç”¨GPU,** é€‰æ‹©`ä¿®æ”¹ > ç¬”è®°æœ¬è®¾ç½®`\n",
    "![image.png](./assets/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e26f4cb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* `ç¡¬ä»¶åŠ é€Ÿå™¨ > GPU`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80291f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image.png](./assets/image1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be6945d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "åœ¨ç¬”è®°ä¸­, æˆ‘ä»¬éœ€è¦ç”Ÿæˆä¸€ä¸ªå›æ”¾è§†é¢‘. å› æ­¤åœ¨Colab(æˆ–ä½ æœ¬åœ°çš„jupyter)ä¸­, **æˆ‘ä»¬éœ€è¦ä¸€ä¸ªè™šæ‹Ÿå±å¹•èƒ½æ¸²æŸ“ç¯å¢ƒ**(è®°å½•è§†é¢‘å¸§).\n",
    "\n",
    "ä¸‹é¢çš„å•å…ƒæ ¼å°†å®‰è£…è™šæ‹Ÿå±å¹•åº“å¹¶åˆ›å»ºå’Œè¿è¡Œè™šæ‹Ÿå±å¹•. ğŸ–¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573b000",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!apt install gitlfs ffmpeg\n",
    "# å¦‚æœä½ ä½¿ç”¨IDE(ä¾‹å¦‚PyCharmæˆ–VS Code)å°†ä¸éœ€è¦è¿™äº›æ­¥éª¤.\n",
    "!apt install python-opengl xvfb \n",
    "!pip install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9823ea2c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# åˆ›å»ºè™šæ‹Ÿå±å¹•.\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "virtual_display = Display(visible=False, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c26a71",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç¬¬1æ­¥: å®‰è£…ä¾èµ–é¡¹ ğŸ”½\n",
    "ç¬¬ä¸€æ­¥æ˜¯å®‰è£…å¤šä¸ªä¾èµ–é¡¹:\n",
    "* `gym`: åŒ…å«Cartpole-v1, PixelCopterå’ŒPongç¯å¢ƒ.\n",
    "* `gym-games`: ä½¿ç”¨PyGameåˆ¶ä½œçš„gymç¯å¢ƒ.\n",
    "* `huggingface_hub`: ğŸ¤— æ˜¯ä¸€ä¸ªä»»ä½•äººéƒ½å¯ä»¥åˆ†äº«å’Œæ¢ç´¢æ¨¡å‹å’Œæ•°æ®é›†çš„åœ°æ–¹. å®ƒæœ‰ç‰ˆæœ¬æ§åˆ¶, è¯„ä¼°, å¯è§†åŒ–å’Œå…¶ä»–åŠŸèƒ½, å¯ä»¥å…è®¸ä½ ç®€å•åœ°ä¸ä»–äººåä½œ.\n",
    "\n",
    "ä½ å¯ä»¥åœ¨è¿™é‡Œçœ‹åˆ°å…¨éƒ¨å¯ç”¨çš„Reinforceæ¨¡å‹. ğŸ‘‰ https://huggingface.co/models?other=reinforce\n",
    "\n",
    "ä½ å¯ä»¥åœ¨è¿™çœ‹åˆ°å…¨éƒ¨å¯ç”¨çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹. ğŸ‘‰ https://huggingface.co/models?pipeline_tag=reinforcement-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8e0050",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install gym\n",
    "!pip install git+https://github.com/ntasfi/PyGame-Learning-Environment.git\n",
    "!pip install git+https://github.com/qlan3/gym-games.git\n",
    "!pip install huggingface_hub\n",
    "!pip install pyglet  # å¦‚æœä½ ä½¿ç”¨IDE, åˆ™ä¸éœ€è¦è¿™äº›æ­¥éª¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d6fb9a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç¬¬2æ­¥: å¯¼å…¥åŒ… ğŸ“¦\n",
    "\n",
    "é™¤äº†å®‰è£…çš„åº“, æˆ‘ä»¬è¿˜ä½¿ç”¨:\n",
    "* `imageio`: ç”Ÿæˆå›æ”¾è§†é¢‘."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31943094",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "import gym\n",
    "import gym_pygame\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb0acf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* è®©æˆ‘ä»¬æ£€æŸ¥æˆ‘ä»¬æ˜¯å¦æœ‰GPU.\n",
    "* å¦‚æœæœ‰, ä½ åº”è¯¥çœ‹åˆ°`cuda:0`æˆ–è€…`mps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e0aa5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19504f29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d526c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "æˆ‘ä»¬ç°åœ¨å·²ç»å‡†å¤‡å¥½å®ç°æˆ‘ä»¬çš„Reinforceç®—æ³• ğŸ”¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f166ac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ç¬¬1ä¸ªæ™ºèƒ½ä½“: ç©CartPole-v1 ğŸ¤–ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8653a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç¬¬3æ­¥: åˆ›å»ºå¹¶ç†è§£CartPoleç¯å¢ƒ\n",
    "#### [ç¯å¢ƒ ğŸ® ](https://www.gymlibrary.ml/environments/classic_control/cart_pole/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa01ee36",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![cartpole.jpg](./assets/cartpole.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553d754",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ä¸ºä»€ä¹ˆæˆ‘ä»¬ä½¿ç”¨åƒCartPole-v1è¿™æ ·çš„ç®€å•ç¯å¢ƒ?\n",
    "æ­£å¦‚[å¼ºåŒ–å­¦ä¹ æŠ€å·§](https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html)æ‰€è§£é‡Šçš„, å½“ä½ ä»å¤´å¼€å§‹å®ç°æ™ºèƒ½ä½“æ—¶, ä½ éœ€è¦**ç¡®ä¿å®ƒå¯ä»¥æ­£ç¡®å·¥ä½œ, å¹¶åœ¨æ·±å…¥ä¹‹å‰æ‰¾åˆ°ç®€å•ç¯å¢ƒä¸­çš„bug.** å› ä¸ºåœ¨ç®€å•ç¯å¢ƒä¸­æ›´å®¹æ˜“æ‰¾åˆ°bug.\n",
    "> å°è¯•åœ¨ç©å…·é—®é¢˜ä¸Šæœ‰ä¸€äº›\"ç”Ÿå‘½è¿¹è±¡\".\n",
    "\n",
    "> é€šè¿‡åœ¨è¶Šæ¥è¶Šå¤æ‚çš„ç¯å¢ƒä¸Šè¿è¡Œæ¥éªŒè¯å®ç°(ä½ å¯ä»¥å’ŒRL zooçš„ç»“æœè¿›è¡Œæ¯”è¾ƒ). ä½ é€šå¸¸éœ€è¦ä¸ºè¯¥æ­¥éª¤è¿è¡Œè¶…å‚æ•°ä¼˜åŒ–.\n",
    "\n",
    "---\n",
    "\n",
    "#### CartPole-v1ç¯å¢ƒ\n",
    "\n",
    "> ä¸€æ ¹æ†é€šè¿‡ä¸€ä¸ªæœªé©±åŠ¨çš„æ¥å¤´è¿æ¥åˆ°æ¨è½¦ä¸Š, è¯¥æ¨è½¦æ²¿ç€æ— æ‘©æ“¦çš„è½¨é“ç§»åŠ¨. æ‘†é”¤ç›´ç«‹æ”¾ç½®åœ¨æ¨è½¦ä¸Š, ç›®æ ‡æ˜¯é€šè¿‡åœ¨æ¨è½¦ä¸Šæ–½åŠ å·¦å³æ–¹å‘çš„åŠ›, ä½¿æ†ä¿æŒå¹³è¡¡.\n",
    "\n",
    "æ‰€ä»¥, æˆ‘ä»¬ä»CartPole-v1å¼€å§‹. ç›®æ ‡æ˜¯å‘å·¦æˆ–è€…å‘å³æ¨åŠ¨è½¦è¾†, **ä½¿æ†ä¿æŒå¹³è¡¡.**\n",
    "\n",
    "å¦‚æœå‡ºç°ä»¥ä¸‹çš„æƒ…å†µ, åˆ™è¯¥å±€æ¸¸æˆç»“æŸ:\n",
    "* æ†çš„å€¾è§’è¶…è¿‡Â±12Ëš\n",
    "* æ¨è½¦çš„ä½ç½®å˜åŒ–è¶…è¿‡Â±2.4\n",
    "* æ¯è½®æ¸¸æˆè¶…è¿‡500æ­¥\n",
    "\n",
    "æ†ä¿æŒå¹³è¡¡çš„æ¯ä¸ªæ—¶é—´æ­¥, æˆ‘ä»¬éƒ½ä¼šå¾—åˆ°+1çš„å¥–åŠ±åˆ†æ•° ğŸ’°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f28ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env_id = 'CartPole-v1'\n",
    "# åˆ›å»ºç¯å¢ƒ.\n",
    "env = gym.make(env_id)\n",
    "\n",
    "# åˆ›å»ºè¯„ä¼°ç¯å¢ƒ.\n",
    "eval_env = gym.make(env_id)\n",
    "\n",
    "# è·å–çŠ¶æ€ç©ºé—´å’ŒåŠ¨ä½œç©ºé—´çš„å¤§å°.\n",
    "s_size = env.observation_space.shape[0]\n",
    "a_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f03892",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('_' * 5 + 'å¯è§‚å¯Ÿçš„ç¯å¢ƒ' + '_' * 5, end='\\n\\n')\n",
    "print('å¯è§‚å¯Ÿçš„ç¯å¢ƒå‘é‡çš„å½¢çŠ¶', s_size)\n",
    "print('éšæœºé‡‡æ ·ç¯å¢ƒ', env.observation_space.sample())  # è·å¾—ä¸€ä¸ªéšæœºçš„å¯è§‚å¯Ÿç¯å¢ƒç©ºé—´."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a62583",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('_' * 5 + 'åŠ¨ä½œç©ºé—´' + '_' * 5, end='\\n\\n')\n",
    "print('åŠ¨ä½œçš„æ€»æ•°', a_size)\n",
    "print('éšæœºåŠ¨ä½œ', env.action_space.sample())  # è·å¾—ä¸€ä¸ªéšæœºçš„åŠ¨ä½œ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce9110",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç¬¬4æ­¥: è®©æˆ‘ä»¬æ„å»ºReinforceæ¶æ„\n",
    "æ­¤å®ç°åŸºäºä¸¤ä¸ªå®ç°:\n",
    "* [PyTorchå®˜æ–¹å¼ºåŒ–å­¦ä¹ ç¤ºä¾‹](https://github.com/pytorch/examples/blob/main/reinforcement_learning/reinforce.py)\n",
    "* [Udacityçš„Reinforceç®—æ³•](https://github.com/udacity/deep-reinforcement-learning/blob/master/reinforce/REINFORCE.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37237d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image.png](./assets/image2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd938180",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "æ‰€ä»¥æˆ‘ä»¬éœ€è¦:\n",
    "* ä¸¤ä¸ªå…¨è¿æ¥å±‚(fc1å’Œfc2).\n",
    "* ä½¿ç”¨ReLUä½œä¸ºå…¨è¿æ¥å±‚fc1çš„æ¿€æ´»å‡½æ•°.\n",
    "* ä½¿ç”¨Softmaxè¾“å‡ºåŠ¨ä½œçš„æ¦‚ç‡åˆ†å¸ƒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ccb0d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, s_size, a_size, h_size):\n",
    "        super(Policy, self).__init__()\n",
    "        # åˆ›å»ºä¸¤ä¸ªå…¨è¿æ¥å±‚.\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"å®šä¹‰å‰å‘ä¼ æ’­.\"\"\"\n",
    "        # çŠ¶æ€è¾“å…¥åˆ°fc1, ç„¶åä½¿ç”¨ReLUæ¿€æ´».\n",
    "        \n",
    "        # fc1è¾“å‡ºåˆ°fc2.\n",
    "        \n",
    "        # æœ€åä½¿ç”¨softmaxæ¿€æ´»è¾“å‡º.\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"ç»™å®šä¸€ä¸ªçŠ¶æ€è·å¾—ä¸€ä¸ªåŠ¨ä½œ.\"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        probs = self.forward(state)\n",
    "        m = Categorical(probs)\n",
    "        action = np.argmax(m)\n",
    "\n",
    "        return action.item(), m.log_prob(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64797a2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c57e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, s_size, a_size, h_size):\n",
    "        super(Policy, self).__init__()\n",
    "        # åˆ›å»ºä¸¤ä¸ªå…¨è¿æ¥å±‚.\n",
    "        self.fc1 = nn.Linear(s_size, h_size)\n",
    "        self.fc2 = nn.Linear(h_size, a_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"å®šä¹‰å‰å‘ä¼ æ’­.\"\"\"\n",
    "        # çŠ¶æ€è¾“å…¥åˆ°fc1, ç„¶åä½¿ç”¨ReLUæ¿€æ´».\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # fc1è¾“å‡ºåˆ°fc2.\n",
    "        x = self.fc2(x)\n",
    "        # æœ€åä½¿ç”¨softmaxæ¿€æ´»è¾“å‡º.\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"ç»™å®šä¸€ä¸ªçŠ¶æ€è·å¾—ä¸€ä¸ªåŠ¨ä½œ.\"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        probs = self.forward(state)\n",
    "        m = Categorical(probs)\n",
    "        action = np.argmax(m)\n",
    "\n",
    "        return action.item(), m.log_prob(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15479e8e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "æˆ‘è¿™é‡Œæœ‰ä¸€ä¸ªé”™è¯¯, ä½ èƒ½çŒœåˆ°åœ¨å“ªé‡Œå—?\n",
    "* ä¸ºäº†æ‰¾åˆ°ç­”æ¡ˆ, è®©æˆ‘ä»¬å‰å‘ä¼ æ’­:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81803e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "debug_policy = Policy(s_size, a_size, 64).to(device)\n",
    "debug_policy.act(env.reset())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a489633",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* è¿™é‡Œæˆ‘ä»¬çœ‹åˆ°é”™è¯¯è¯´ `ValueError: The value argument to log_prob must be a Tensor`\n",
    "* è¿™è¡¨æ˜`m.log_prob(action)`ä¸­çš„`action`å¿…é¡»æ˜¯ä¸€ä¸ªå¼ é‡, **ä½†ç°åœ¨ä¸æ˜¯.**\n",
    "* ä½ çŸ¥é“è¿™æ˜¯ä¸ºä»€ä¹ˆå—? æ£€æŸ¥å‡½æ•°`act`å¹¶å°è¯•æŸ¥çœ‹å®ƒä¸ºä»€ä¹ˆä¸æ­£å¸¸å·¥ä½œ.\n",
    "\n",
    "å»ºè®® ğŸ’¡: è¿™ä¸ªå®ç°ä¸­æœ‰é—®é¢˜. è®°ä½æˆ‘ä»¬çš„å‡½æ•°`act`æ˜¯**æˆ‘ä»¬æƒ³ä»åŠ¨ä½œçš„æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ªåŠ¨ä½œ.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefea48a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ç­”æ¡ˆ\n",
    "* ç”±äº**æˆ‘ä»¬æƒ³ä»åŠ¨ä½œçš„æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·ä¸€ä¸ªåŠ¨ä½œ**, ä½†æˆ‘ä»¬ä¸èƒ½ä½¿ç”¨`action = np.argmax(m)`, å› ä¸ºå®ƒæ€»æ˜¯è¾“å‡ºå…·æœ‰æœ€é«˜æ¦‚ç‡çš„åŠ¨ä½œ.\n",
    "* æˆ‘ä»¬éœ€è¦æ›¿æ¢æˆ`action = m.sample()`, å®ƒå°†ä»æ¦‚ç‡åˆ†å¸ƒ$P(.|s)$ä¸­é‡‡æ ·ä¸€ä¸ªåŠ¨ä½œå‡ºæ¥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f9333",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, s_size, a_size, h_size):\n",
    "        super(Policy, self).__init__()\n",
    "        # åˆ›å»ºä¸¤ä¸ªå…¨è¿æ¥å±‚.\n",
    "        self.fc1 = nn.Linear(s_size, h_size)\n",
    "        self.fc2 = nn.Linear(h_size, a_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"å®šä¹‰å‰å‘ä¼ æ’­.\"\"\"\n",
    "        # çŠ¶æ€è¾“å…¥åˆ°fc1, ç„¶åä½¿ç”¨ReLUæ¿€æ´».\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # fc1è¾“å‡ºåˆ°fc2.\n",
    "        x = self.fc2(x)\n",
    "        # æœ€åä½¿ç”¨softmaxæ¿€æ´»è¾“å‡º.\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"ç»™å®šä¸€ä¸ªçŠ¶æ€è·å¾—ä¸€ä¸ªåŠ¨ä½œ.\"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        probs = self.forward(state).cpu()\n",
    "        m = Categorical(probs)\n",
    "        action = m.sample()\n",
    "\n",
    "        return action.item(), m.log_prob(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0102e7e8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "é€šè¿‡ä½¿ç”¨CartPole, è°ƒè¯•èµ·æ¥æ›´åŠ å®¹æ˜“, å› ä¸º**æˆ‘ä»¬çŸ¥é“bugæ¥è‡ªæˆ‘ä»¬çš„ä»£ç è€Œä¸æ˜¯æˆ‘ä»¬çš„ç¯å¢ƒ.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2fe649",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç¬¬5æ­¥: æ„å»ºReinforceè®­ç»ƒç®—æ³•\n",
    "* ä¸ä¼ªä»£ç ç›¸å, æˆ‘ä»¬åœ¨æ¯è½®(episode)ä¹‹åæ›´æ–°ç­–ç•¥, **è€Œä¸æ˜¯ä½¿ç”¨ä¸€ä¸ªæ‰¹æ¬¡çš„è½®(batch of episodes).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70a514",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image.png](./assets/image3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed18fd15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦æœ€å°åŒ–æŸå¤±? ä½ è¯´çš„æ˜¯æ¢¯åº¦ä¸Šå‡(Gradient Ascent)è€Œä¸æ˜¯æ¢¯åº¦ä¸‹é™(Gradient Descent)?\n",
    "* æˆ‘ä»¬æƒ³æœ€å¤§åŒ–æˆ‘ä»¬çš„ç›®æ ‡å‡½æ•°$J(\\theta)$, ä½†æ˜¯åœ¨PyTorchä¸­å°±åƒåœ¨TensorFlowä¸­ä¸€æ ·, **æœ€å¥½æ˜¯æœ€å°åŒ–ç›®æ ‡å‡½æ•°.**\n",
    "    * å› æ­¤, å‡è®¾æˆ‘ä»¬æƒ³åœ¨æŸä¸ªæ—¶é—´æ­¥åŠ å¼ºåŠ¨ä½œ$a_3$. åœ¨è®­ç»ƒè¿™ä¸ªåŠ¨ä½œä¹‹å‰, å®ƒçš„æ¦‚ç‡æ˜¯0.25.\n",
    "    * æ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¿®æ”¹$\\theta$, ä½¿å¾—$\\pi_\\theta(a_3|s;\\theta)>0.25$\n",
    "    * å› ä¸ºæ¦‚ç‡å’Œå¿…é¡»ä¸º1, æ‰€ä»¥æœ€å¤§åŒ–$\\pi_\\theta(a_3|s;\\theta)$å°†**æœ€å°åŒ–å…¶ä»–åŠ¨ä½œçš„æ¦‚ç‡.**\n",
    "    * æ‰€ä»¥æˆ‘ä»¬åº”è¯¥å‘Šè¯‰PyTorchå»**æœ€å°åŒ–$1-\\pi_\\theta(a_3|s;\\theta)$.**\n",
    "    * å½“$\\pi_\\theta(a_3|s;\\theta)$è¶‹è¿‘1æ—¶, æŸå¤±å‡½æ•°è¶‹è¿‘0.\n",
    "    * æ‰€ä»¥è¿™ç­‰åŒäºæœ€å¤§åŒ–æ¢¯åº¦$\\pi_\\theta(a_3|s;\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb5941",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reinforce(policy, optimizer, n_training_episodes, max_t, gamma, print_every):\n",
    "    # å¸®åŠ©æˆ‘ä»¬è®¡ç®—è®­ç»ƒè¿‡ç¨‹ä¸­çš„åˆ†æ•°.\n",
    "    score_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    # ä¼ªä»£ç ç¬¬3è¡Œ.\n",
    "    for i_episode in range(1, n_training_episodes + 1):\n",
    "        saved_log_probs = []\n",
    "        rewards = []\n",
    "        state =  # TODO: é‡ç½®ç¯å¢ƒ.\n",
    "        # ä¼ªä»£ç ç¬¬4è¡Œ.\n",
    "        for t in range(max_t):\n",
    "            action, log_prob =  # TODO: è·å–ä¸€ä¸ªåŠ¨ä½œ.\n",
    "            saved_log_probs.append(log_prob)\n",
    "            state, reward, done, info =  # TODO: åœ¨ç¯å¢ƒä¸Šæ‰§è¡ŒåŠ¨ä½œ.\n",
    "            rewards.append(reward)\n",
    "            if done:\n",
    "                break\n",
    "        score_deque.append(sum(rewards))\n",
    "        scores.append(sum(rewards))\n",
    "\n",
    "        # ä¼ªä»£ç ç¬¬6è¡Œ: è®¡ç®—å¥–ç½šå€¼.\n",
    "        # è¿™é‡Œæˆ‘ä»¬è®¡ç®—è¡°å‡, ä¾‹å¦‚: [0.99^1, 0.99^2, 0.99^3, ..., 0.99^len(rewards)]\n",
    "        discounts = [gamma ** i for i in range(len(rewards) + 1)]\n",
    "        # æˆ‘ä»¬è®¡ç®—å¥–ç½šå€¼çš„æ€»å’Œsum(gamma[t] * reward[t])\n",
    "        R = sum([a * b for a, b in zip( , )])  # TODO: æˆ‘ä»¬éœ€è¦åœ¨å‡½æ•°zip()ä¸­å¡«å…¥ä»€ä¹ˆ, è¯·è®°ä½æˆ‘ä»¬è®¡ç®—gamma[t] * reward[t]\n",
    "\n",
    "        # ä¼ªä»£ç ç¬¬7è¡Œ.\n",
    "        policy_loss = []\n",
    "        for log_prob in saved_log_probs:\n",
    "            policy_loss.append(-log_prob * R)\n",
    "        policy_loss = torch.cat(policy_loss).sum()\n",
    "\n",
    "        # ä¼ªä»£ç ç¬¬8è¡Œ: PyTorchæ‰§è¡Œè®¡ç®—.\n",
    "        optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i_episode % print_every == 0:\n",
    "            print('ç¬¬{}è½®\\t å¹³å‡å¾—åˆ†{:.2f}'.format(i_episode, np.mean(score_deque)))\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7fe31",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### ç­”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048229b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reinforce(policy, optimizer, n_training_episodes, max_t, gamma, print_every):\n",
    "    # å¸®åŠ©æˆ‘ä»¬è®¡ç®—è®­ç»ƒè¿‡ç¨‹ä¸­çš„åˆ†æ•°.\n",
    "    score_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    # ä¼ªä»£ç ç¬¬3è¡Œ.\n",
    "    for i_episode in range(1, n_training_episodes + 1):\n",
    "        saved_log_probs = []\n",
    "        rewards = []\n",
    "        state = env.reset()\n",
    "        # ä¼ªä»£ç ç¬¬4è¡Œ.\n",
    "        for t in range(max_t):\n",
    "            action, log_prob = policy.act(state)\n",
    "            saved_log_probs.append(log_prob)\n",
    "            state, reward, done, info = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            if done:\n",
    "                break\n",
    "        score_deque.append(sum(rewards))\n",
    "        scores.append(sum(rewards))\n",
    "\n",
    "        # ä¼ªä»£ç ç¬¬6è¡Œ: è®¡ç®—å¥–ç½šå€¼.\n",
    "        # è¿™é‡Œæˆ‘ä»¬è®¡ç®—è¡°å‡, ä¾‹å¦‚: [0.99^1, 0.99^2, 0.99^3, ..., 0.99^len(rewards)]\n",
    "        discounts = [gamma ** i for i in range(len(rewards) + 1)]\n",
    "        # æˆ‘ä»¬è®¡ç®—å¥–ç½šå€¼çš„æ€»å’Œsum(gamma[t] * reward[t])\n",
    "        R = sum([a * b for a, b in zip(discounts, rewards)])\n",
    "\n",
    "        # ä¼ªä»£ç ç¬¬7è¡Œ.\n",
    "        policy_loss = []\n",
    "        for log_prob in saved_log_probs:\n",
    "            policy_loss.append(-log_prob * R)\n",
    "        policy_loss = torch.cat(policy_loss).sum()\n",
    "\n",
    "        # ä¼ªä»£ç ç¬¬8è¡Œ: PyTorchæ‰§è¡Œè®¡ç®—.\n",
    "        optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i_episode % print_every == 0:\n",
    "            print('ç¬¬{}è½®\\t å¹³å‡å¾—åˆ†{:.2f}'.format(i_episode, np.mean(score_deque)))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d9713c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### è®­ç»ƒ\n",
    "* æˆ‘ä»¬å·²ç»å‡†å¤‡å¥½è®­ç»ƒæˆ‘ä»¬çš„æ™ºèƒ½ä½“.\n",
    "* é¦–å…ˆ, æˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªåŒ…å«æ‰€æœ‰è®­ç»ƒè¶…å‚æ•°çš„å˜é‡."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa90a3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cartpole_hyperparameters = {\n",
    "    'h_size': 16,\n",
    "    'n_training_episodes': 1000,\n",
    "    'n_evaluation_episodes': 10,\n",
    "    'max_t': 1000,\n",
    "    'gamma': 1.0,\n",
    "    'lr': 1e-2,\n",
    "    'env_id': env_id,\n",
    "    'state_space': s_size,\n",
    "    'action_space': a_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a78c85b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ¨¡å‹å¹¶å°†å®ƒæ”¾åˆ°ç¡¬ä»¶è®¾å¤‡ä¸Š.\n",
    "cartpole_policy = Policy(cartpole_hyperparameters['state_space'],\n",
    "                         cartpole_hyperparameters['action_space'],\n",
    "                         cartpole_hyperparameters['h_size']).to(device)\n",
    "cartpole_optimizer = optim.Adam(cartpole_policy.parameters(), lr=cartpole_hyperparameters['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78258a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores = reinforce(cartpole_policy,\n",
    "                   cartpole_optimizer,\n",
    "                   cartpole_hyperparameters['n_training_episodes'],\n",
    "                   cartpole_hyperparameters['max_t'],\n",
    "                   cartpole_hyperparameters['gamma'],\n",
    "                   100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1a89a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç¬¬6æ­¥:  å®šä¹‰è¯„ä¼°å‡½æ•° ğŸ“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2165264e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_agent(env, max_steps, n_eval_episodes, policy):\n",
    "    \"\"\"ç”¨`n_eval_episodes`è½®è¯„ä¼°æ™ºèƒ½ä½“, å¹¶è¿”å›å¥–åŠ±çš„å‡å€¼å’Œæ ‡å‡†å·®.\n",
    "\n",
    "    Args:\n",
    "        env: è¯„ä¼°ç¯å¢ƒ.\n",
    "        max_steps: æ¯è½®çš„æœ€å¤§æ­¥æ•°.\n",
    "        n_eval_episodes: æµ‹è¯•çš„æ€»è½®æ•°.\n",
    "        policy: Reinforceæ™ºèƒ½ä½“.\n",
    "\n",
    "    Returns:\n",
    "        å¥–åŠ±çš„å‡å€¼å’Œæ ‡å‡†å·®.\n",
    "    \"\"\"\n",
    "    episode_rewards = []\n",
    "\n",
    "    for episode in range(n_eval_episodes):\n",
    "        state = env.reset()\n",
    "        total_rewards_ep = 0\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            action, _ = policy.act(state)\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "            total_rewards_ep += reward\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "            state = new_state\n",
    "        episode_rewards.append(total_rewards_ep)\n",
    "        \n",
    "    mean_reward = np.mean(episode_rewards)\n",
    "    std_reward = np.std(episode_rewards)\n",
    "    \n",
    "    return mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606dd7f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç¬¬7æ­¥: è¯„ä¼°æˆ‘ä»¬çš„æ™ºèƒ½ä½“ ğŸ“ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50db69b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_agent(eval_env,\n",
    "               cartpole_hyperparameters['max_t'],\n",
    "               cartpole_hyperparameters['n_evaluation_episodes'],\n",
    "               cartpole_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f85ce5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç¬¬8æ­¥(ä¸æ¶‰åŠæ ¸å¿ƒå†…å®¹, å¯é€‰): å‘å¸ƒæˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹åˆ°Hubä¸Š ğŸš€\n",
    "ç°åœ¨æˆ‘ä»¬çœ‹åˆ°ç»è¿‡è®­ç»ƒä¹‹åå¾—åˆ°äº†å¾ˆæ£’çš„ç»“æœ, æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€è¡Œä»£ç å‘å¸ƒæˆ‘ä»¬è®­ç»ƒçš„æ¨¡å‹åˆ°hub ğŸ¤— ä¸Š.\n",
    "\n",
    "è¿™æœ‰ä¸€ä¸ªæ¨¡å‹å¡çš„ä¾‹å­:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfdcfb1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image.png](./assets/image4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120778aa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "åœ¨åº•å±‚, Hubä½¿ç”¨åŸºäºgitçš„ä»“åº“(å³ä½¿ä½ ä¸çŸ¥é“ä»€ä¹ˆæ˜¯gitä¹Ÿä¸ç”¨æ‹…å¿ƒ), è¿™æ„å‘³ç€ä½ å¯ä»¥åœ¨å®éªŒå’Œæé«˜ä½ çš„æ™ºèƒ½ä½“ä»¥åæ›´æ–°æ–°ç‰ˆæœ¬çš„æ¨¡å‹."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c80bdb6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### å‘å¸ƒåˆ°Hugging Face Hub\n",
    "#### è¯·å‹¿ä¿®æ”¹ä¸‹é¢çš„ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a4631d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from huggingface_hub import HfApi, Repository\n",
    "from huggingface_hub.repocard import metadata_eval_result, metadata_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52fadf3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def record_video(env, policy, out_directory, fps=30):\n",
    "    images = []  \n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    img = env.render(mode='rgb_array')\n",
    "    images.append(img)\n",
    "    \n",
    "    while not done:\n",
    "        # åœ¨ç»™å®šçŠ¶æ€ä¸‹, é‡‡å–å…·æœ‰æœ€å¤§æœŸæœ›å¥–åŠ±çš„åŠ¨ä½œ(ç´¢å¼•).\n",
    "        action, _ = policy.act(state)\n",
    "        state, reward, done, info = env.step(action) # æˆ‘ä»¬ç›´æ¥ä½¿ç”¨next_state = stateæ¥è®°å½•é¡ºåº(recording logic).\n",
    "        img = env.render(mode='rgb_array')\n",
    "        images.append(img)\n",
    "        \n",
    "    imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806349d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def package_to_hub(repo_id,\n",
    "                   model,\n",
    "                   hyperparameters,\n",
    "                   eval_env,\n",
    "                   video_fps=30,\n",
    "                   local_repo_path='hub',\n",
    "                   commit_message='Push Reinforce agent to Hub',\n",
    "                   token=None):\n",
    "    _, repo_name = repo_id.split('/')\n",
    "\n",
    "    # ç¬¬0æ­¥: å…‹éš†æˆ–åˆ›å»ºä»“åº“.\n",
    "    # åˆ›å»ºä»“åº“(å¦‚æœå†…å®¹ä¸ä¸ºç©º, åˆ™å…‹éš†).\n",
    "    api = HfApi()\n",
    "\n",
    "    repo_url = api.create_repo(repo_id=repo_id,\n",
    "                               token=token,\n",
    "                               private=False,\n",
    "                               exist_ok=True)\n",
    "\n",
    "    # git pull\n",
    "    repo_local_path = Path(local_repo_path) / repo_name\n",
    "    repo = Repository(repo_local_path, clone_from=repo_url, use_auth_token=True)\n",
    "    repo.git_pull()\n",
    "\n",
    "    repo.lfs_track(['*.mp4'])\n",
    "\n",
    "    # ç¬¬1æ­¥: ä¿å­˜æ¨¡å‹.\n",
    "    torch.save(model, os.path.join(repo_local_path, 'model.pt'))\n",
    "\n",
    "    # ç¬¬2æ­¥: ä¿å­˜è¶…å‚æ•°åˆ°JSON.\n",
    "    with open(Path(repo_local_path) / 'hyperparameters.json', 'w') as outfile:\n",
    "        json.dump(hyperparameters, outfile)\n",
    "\n",
    "    # ç¬¬3æ­¥: è¯„ä¼°æ¨¡å‹å¹¶æ„å»ºJSON.\n",
    "    mean_reward, std_reward = evaluate_agent(eval_env,\n",
    "                                             hyperparameters['max_t'],\n",
    "                                             hyperparameters['n_evaluation_episodes'],\n",
    "                                             model)\n",
    "\n",
    "    # é¦–å…ˆ, è·å–å½“å‰æ—¶é—´.\n",
    "    eval_datetime = datetime.datetime.now()\n",
    "    eval_form_datetime = eval_datetime.isoformat()\n",
    "\n",
    "    evaluate_data = {\n",
    "        'env_id': hyperparameters['env_id'],\n",
    "        'mean_reward': mean_reward,\n",
    "        'n_evaluation_episodes': hyperparameters['n_evaluation_episodes'],\n",
    "        'eval_datetime': eval_form_datetime,\n",
    "    }\n",
    "    # å†™å…¥JSONæ–‡ä»¶.\n",
    "    with open(Path(repo_local_path) / 'results.json', 'w') as outfile:\n",
    "        json.dump(evaluate_data, outfile)\n",
    "\n",
    "    # ç¬¬4æ­¥: åˆ›å»ºæ¨¡å‹å¡.\n",
    "    env_name = hyperparameters['env_id']\n",
    "\n",
    "    metadata = {\n",
    "        'tags': [\n",
    "            env_name,\n",
    "            'reinforce',\n",
    "            'reinforcement-learning',\n",
    "            'custom-implementation',\n",
    "            'deep-rl-class'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # æ·»åŠ è¯„ä¼°.\n",
    "    eval = metadata_eval_result(model_pretty_name=repo_name,\n",
    "                                task_pretty_name='reinforcement-learning',\n",
    "                                task_id='reinforcement-learning',\n",
    "                                metrics_pretty_name='mean_reward',\n",
    "                                metrics_id='mean_reward',\n",
    "                                metrics_value=f'{mean_reward:.2f} +/- {std_reward:.2f}',\n",
    "                                dataset_pretty_name=env_name,\n",
    "                                dataset_id=env_name)\n",
    "\n",
    "    # åˆå¹¶æ‰€æœ‰çš„å­—å…¸{metadata, eval}.\n",
    "    metadata = {**metadata, **eval}\n",
    "\n",
    "    model_card = f'''\n",
    "      # ä½¿ç”¨**Reinforce**æ™ºèƒ½ä½“æ¥ç©**{env_id}**\n",
    "      è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨**Reinforce**è®­ç»ƒæœ‰ç´ çš„æ¨¡å‹ç©**{env_id}**.\n",
    "      è¦å­¦ä¹ ä½¿ç”¨è¿™ä¸ªæ¨¡å‹å¹¶è®­ç»ƒä½ çš„æ¨¡å‹, è¯·æŸ¥é˜…æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ç¬¬5å•å…ƒ: https://github.com/huggingface/deep-rl-class/tree/main/unit5\n",
    "      '''\n",
    "\n",
    "    readme_path = repo_local_path / 'README.md'\n",
    "\n",
    "    if readme_path.exists():\n",
    "        with readme_path.open('r', encoding='utf8') as f:\n",
    "            readme = f.read()\n",
    "    else:\n",
    "        readme = model_card\n",
    "\n",
    "    with readme_path.open('w', encoding='utf-8') as f:\n",
    "        f.write(readme)\n",
    "\n",
    "    # ä¿å­˜æˆ‘ä»¬çš„è¯„ä¼°ä¿¡æ¯åˆ°READMEçš„å…ƒæ•°æ®.\n",
    "    metadata_save(readme_path, metadata)\n",
    "\n",
    "    # ç¬¬5æ­¥: å½•åˆ¶å›æ”¾è§†é¢‘.\n",
    "    video_path = repo_local_path / 'replay.mp4'\n",
    "    record_video(env, model, video_path, video_fps)\n",
    "\n",
    "    # å‘å¸ƒåˆ°Hub.\n",
    "    print(f'å‘å¸ƒ {repo_name} åˆ°ä½ çš„Hugging Face Hub')\n",
    "    repo.push_to_hub(commit_message=commit_message)\n",
    "\n",
    "    print(f'ä½ çš„æ¨¡å‹å·²ç»å‘å¸ƒåˆ°Hub. ä½ å¯ä»¥ç‚¹å‡»é“¾æ¥æŸ¥çœ‹çš„ä½ çš„æ¨¡å‹: {repo_url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5ab08c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "é€šè¿‡ä½¿ç”¨`package_to_hub`, **ä½ å¯ä»¥è¯„ä¼°, è®°å½•å›æ”¾è§†é¢‘, ç”Ÿæˆæ™ºèƒ½ä½“çš„æ¨¡å‹å¡å¹¶æŠŠå®ƒå‘å¸ƒåˆ°hub.**\n",
    "\n",
    "çœ‹è¿™è¾¹:\n",
    "\n",
    "* ä½ å¯ä»¥**å±•ç¤ºæˆ‘ä»¬çš„ä½œå“** ğŸ”¥\n",
    "* ä½ å¯ä»¥**å¯è§†åŒ–æ™ºèƒ½ä½“çš„æ´»åŠ¨** ğŸ‘€\n",
    "* ä½ å¯ä»¥**ä¸ç¤¾åŒºåˆ†äº«å…¶ä»–äººä¹Ÿå¯ä»¥ä½¿ç”¨çš„æ™ºèƒ½ä½“** ğŸ’¾\n",
    "* ä½ å¯ä»¥**è®¿é—®æ’è¡Œæ¦œğŸ†ä»¥æŸ¥çœ‹ä½ çš„æ™ºèƒ½ä½“å’Œä½ åŒå­¦çš„æ™ºèƒ½ä½“ç›¸æ¯”å¦‚ä½•** ğŸ‘‰ https://huggingface.co/spaces/chrisjay/Deep-Reinforcement-Learning-Leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42a5b4e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ä¸ºäº†èƒ½åˆ†äº«ä½ çš„æ¨¡å‹åˆ°ç¤¾åŒº, æœ‰ä»¥ä¸‹ä¸‰ä¸ªæ­¥éª¤éœ€è¦åš:\n",
    "\n",
    "1âƒ£ï¸ (å¦‚æœæ²¡æœ‰å®Œæˆ)åˆ›å»ºä¸€ä¸ªHugging Faceè´¦æˆ· â¡ https://huggingface.co/join\n",
    "\n",
    "2âƒ£ï¸ ç™»é™†è´¦æˆ·, ç„¶åä½ éœ€è¦ä¿å­˜ä¸€ä¸ªHugging Faceçš„èº«ä»½éªŒè¯ä»¤ç‰Œ(token).\n",
    "\n",
    "* åˆ›å»ºä¸€ä¸ªæ–°çš„å…·æœ‰**å†™å…¥è§„åˆ™**çš„ä»¤ç‰Œ(https://huggingface.co/settings/tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a39d19",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image.png](./assets/image5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b3ace",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb7896",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "å¦‚æœä½ ä½¿ç”¨IDE, ä¹Ÿå¯åœ¨ç»ˆç«¯ä¸­ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa1f47d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f0321b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3âƒ£ï¸ æˆ‘ä»¬ç°åœ¨å‡†å¤‡å¥½ä½¿ç”¨`package_to_hub()`å‘å¸ƒæˆ‘ä»¬è®­ç»ƒçš„æ™ºèƒ½ä½“åˆ°ğŸ¤— Hub ğŸ”¥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9707b350",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "repo_id = ''  # TODO: å®šä¹‰ä½ çš„ä»“åº“id:{ä½ çš„ç”¨æˆ·å/Reinforce-{model-id}}.\n",
    "package_to_hub(repo_id,\n",
    "               cartpole_policy,  # æˆ‘ä»¬æƒ³ä¿å­˜çš„æ¨¡å‹.\n",
    "               cartpole_hyperparameters,  # è¶…å‚æ•°.\n",
    "               eval_env,  # è¯„ä¼°ç¯å¢ƒ.\n",
    "               video_fps=30,\n",
    "               local_repo_path='hub',\n",
    "               commit_message='Push Reinforce agent to the Hub')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a35993",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ç°åœ¨æˆ‘ä»¬å°è¯•æˆ‘ä»¬å®ç°çš„æ™ºèƒ½ä½“çš„é²æ£’æ€§, è®©æˆ‘ä»¬å®éªŒä¸€ä¸‹æ›´å¤æ‚çš„ç¯å¢ƒä¾‹å¦‚:\n",
    "* PixelCopter\n",
    "* Pong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d9b4a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ç¬¬2ä¸ªæ™ºèƒ½ä½“: PixelCopter ğŸš\n",
    "### ç¬¬1æ­¥: ç ”ç©¶PixelCopterç¯å¢ƒ ğŸ‘€\n",
    "* [ç¯å¢ƒçš„æ–‡æ¡£](https://pygame-learning-environment.readthedocs.io/en/latest/user/games/pixelcopter.html)\n",
    "\n",
    "å¯è§‚å¯Ÿçš„ç¯å¢ƒç©ºé—´çš„å½¢çŠ¶(7,) ğŸ‘€:\n",
    "* ç©å®¶yåæ ‡\n",
    "* ç©å®¶çš„é€Ÿåº¦\n",
    "* ç©å®¶åˆ°åœ°é¢çš„è·ç¦»\n",
    "* ç©å®¶åˆ°é¡¶éƒ¨çš„è·ç¦»\n",
    "* ä¸‹ä¸€ä¸ªæ–¹å—xåæ ‡åˆ°ç©å®¶çš„è·ç¦»\n",
    "* ä¸‹ä¸€ä¸ªæ–¹å—é¡¶éƒ¨çš„yåæ ‡\n",
    "* ä¸‹ä¸€ä¸ªæ–¹å—åº•éƒ¨çš„yåæ ‡\n",
    "\n",
    "åŠ¨ä½œç©ºé—´æœ‰2ä¸ªå¯ç”¨åŠ¨ä½œ ğŸ®:\n",
    "* å‘ä¸Šç§»åŠ¨,\n",
    "* å‘ä¸‹ç§»åŠ¨.\n",
    "\n",
    "å¥–åŠ±å‡½æ•°(åœ¨æ¯ä¸ªæ—¶é—´æ­¥ç»™äºˆçš„å¥–åŠ±)ğŸ’°:\n",
    "* é€šè¿‡æ¯ä¸ªå‚ç›´æ–¹å—, å®ƒéƒ½ä¼šå¾—åˆ°+1çš„å¥–åŠ±. æ¯æ¬¡éƒ½åˆ°ç»“æŸçŠ¶æ€éƒ½å¾—åˆ°-1çš„æƒ©ç½š."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd5b43b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env_id = 'Pixelcopter-PLE-v0'\n",
    "\n",
    "env = gym.make(env_id)\n",
    "eval_env = gym.make(env_id)\n",
    "\n",
    "s_size = env.observation_space.shape[0]\n",
    "a_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebc085d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç¬¬2æ­¥: å®šä¹‰è¶…å‚æ•° âš™ï¸\n",
    "* å› ä¸ºè¿™ä¸ªç¯å¢ƒæ¯”è¾ƒå¤æ‚, æ‰€ä»¥æˆ‘ä»¬éœ€è¦è°ƒæ•´è¶…å‚æ•°.\n",
    "* ç‰¹åˆ«æ˜¯éšè—å±‚çš„å¤§å°, æˆ‘ä»¬éœ€è¦æ›´å¤šçš„ç¥ç»å…ƒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ca5c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pixelcopter_hyperparameters = {\n",
    "    'h_size': 64,\n",
    "    'n_training_episodes': 50000,\n",
    "    'n_evaluation_episodes': 10,\n",
    "    'max_t': 10000,\n",
    "    'gamma': 0.99,\n",
    "    'lr': 1e-4,\n",
    "    'env_id': env_id,\n",
    "    'state_space': s_size,\n",
    "    'action_space': a_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e98ddc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, s_size, a_size, h_size):\n",
    "        super(Policy, self).__init__()\n",
    "        self.fc1 = nn.Linear(s_size, h_size)\n",
    "        self.fc2 = nn.Linear(h_size, a_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "    def act(self, state):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        probs = self.forward(state).cpu()\n",
    "        m = Categorical(probs)\n",
    "        action = m.sample()\n",
    "\n",
    "        return action.item(), m.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cb2298",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ¨¡å‹å¹¶å°†å®ƒæ”¾åˆ°ç¡¬ä»¶è®¾å¤‡ä¸Š.\n",
    "# torch.manual_seed(50)\n",
    "pixelcopter_policy = Policy(pixelcopter_hyperparameters['state_space'],\n",
    "                            pixelcopter_hyperparameters['action_space'],\n",
    "                            pixelcopter_hyperparameters['h_size']).to(device)\n",
    "pixelcopter_optimizer = optim.Adam(pixelcopter_policy.parameters(), lr=pixelcopter_hyperparameters['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b4f8b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores = reinforce(pixelcopter_policy,\n",
    "                   pixelcopter_optimizer,\n",
    "                   pixelcopter_hyperparameters['n_training_episodes'],\n",
    "                   pixelcopter_hyperparameters['max_t'],\n",
    "                   pixelcopter_hyperparameters['gamma'],\n",
    "                   1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb0019",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "repo_id = ''  # TODO: å®šä¹‰ä½ çš„ä»“åº“id:{ä½ çš„ç”¨æˆ·å/Reinforce-{model-id}}.\n",
    "package_to_hub(repo_id,\n",
    "               pixelcopter_policy,  # æˆ‘ä»¬æƒ³ä¿å­˜çš„æ¨¡å‹.\n",
    "               pixelcopter_hyperparameters,  # è¶…å‚æ•°.\n",
    "               eval_env,  # è¯„ä¼°ç¯å¢ƒ.\n",
    "               video_fps=30,\n",
    "               local_repo_path='hub',\n",
    "               commit_message='Push Reinforce agent to the Hub')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ff61c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ç¬¬3ä¸ªæ™ºèƒ½ä½“: Pong ğŸ¾\n",
    "### ç¬¬1æ­¥: ç ”ç©¶Pongç¯å¢ƒ ğŸ‘€\n",
    "* [ç¯å¢ƒçš„æ–‡æ¡£](https://pygame-learning-environment.readthedocs.io/en/latest/user/games/pong.html)\n",
    "\n",
    "å¯è§‚å¯Ÿçš„ç¯å¢ƒç©ºé—´çš„å½¢çŠ¶(7,) ğŸ‘€:\n",
    "* ç©å®¶yåæ ‡\n",
    "* ç©å®¶çš„é€Ÿåº¦\n",
    "* ç”µè„‘çš„ä½ç½®\n",
    "* çƒçš„xåæ ‡\n",
    "* çƒçš„yåæ ‡\n",
    "* çƒçš„æ°´å¹³é€Ÿåº¦\n",
    "* çƒçš„å‚ç›´é€Ÿåº¦\n",
    "\n",
    "åŠ¨ä½œç©ºé—´æœ‰3ä¸ªå¯ç”¨åŠ¨ä½œ ğŸ®:\n",
    "* å‘ä¸Šç§»åŠ¨,\n",
    "* å‘ä¸‹ç§»åŠ¨,\n",
    "* ä¸ç§»åŠ¨.\n",
    "\n",
    "å¥–åŠ±å‡½æ•°(åœ¨æ¯ä¸ªæ—¶é—´æ­¥ç»™äºˆçš„å¥–åŠ±)ğŸ’°:\n",
    "* æ¯ä¸ªå¯¹æ‰‹æœªæ¥åˆ°çš„çƒ(åœ¨çƒæ‹å), å®ƒéƒ½ä¼šå¾—åˆ°+1çš„å¥–åŠ±. æ¯ä¸ªæœªæ¥åˆ°çš„çƒéƒ½å¾—åˆ°-1çš„æƒ©ç½š."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd685f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env_id = 'Pong-PLE-v0'\n",
    "\n",
    "env = gym.make(env_id)\n",
    "eval_env = gym.make(env_id)\n",
    "\n",
    "s_size = env.observation_space.shape[0]\n",
    "a_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec329f35",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç¬¬2æ­¥: å®šä¹‰è¶…å‚æ•° âš™ï¸\n",
    "* å› ä¸ºè¿™ä¸ªç¯å¢ƒæ¯”è¾ƒå¤æ‚, æ‰€ä»¥æˆ‘ä»¬éœ€è¦è°ƒæ•´è¶…å‚æ•°.\n",
    "* ç‰¹åˆ«æ˜¯éšè—å±‚çš„å¤§å°, æˆ‘ä»¬éœ€è¦æ›´å¤šçš„ç¥ç»å…ƒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a77c6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pong_hyperparameters = {\n",
    "    'h_size': 64,\n",
    "    'n_training_episodes': 20000,\n",
    "    'n_evaluation_episodes': 10,\n",
    "    'max_t': 5000,\n",
    "    'gamma': 0.99,\n",
    "    'lr': 1e-2,\n",
    "    'env_id': env_id,\n",
    "    'state_space': s_size,\n",
    "    'action_space': a_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1ec611",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, s_size, a_size, h_size):\n",
    "        super(Policy, self).__init__()\n",
    "        self.fc1 = nn.Linear(s_size, h_size)\n",
    "        self.fc2 = nn.Linear(h_size, h_size * 2)\n",
    "        self.fc3 = nn.Linear(h_size * 2, a_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "    def act(self, state):\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        probs = self.forward(state).cpu()\n",
    "        m = Categorical(probs)\n",
    "        action = m.sample()\n",
    "\n",
    "        return action.item(), m.log_prob(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1a7512",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç¬¬3æ­¥: è®­ç»ƒæ™ºèƒ½ä½“ ğŸƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b58aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ¨¡å‹å¹¶å°†å®ƒæ”¾åˆ°ç¡¬ä»¶è®¾å¤‡ä¸Š.\n",
    "# torch.manual_seed(50)\n",
    "pong_policy = Policy(pong_hyperparameters['state_space'],\n",
    "                     pong_hyperparameters['action_space'],\n",
    "                     pong_hyperparameters['h_size']).to(device)\n",
    "pong_optimizer = optim.Adam(pong_policy.parameters(), lr=pong_hyperparameters['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ecfc9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores = reinforce(pong_policy,\n",
    "                   pong_optimizer,\n",
    "                   pong_hyperparameters['n_training_episodes'],\n",
    "                   pong_hyperparameters['max_t'],\n",
    "                   pong_hyperparameters['gamma'],\n",
    "                   1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd9a54",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ç¬¬4æ­¥: å‘å¸ƒæˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹åˆ°Hugging Face Hub ğŸ”¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f13afc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "repo_id = ''  # TODO: å®šä¹‰ä½ çš„ä»“åº“id:{ä½ çš„ç”¨æˆ·å/Reinforce-{model-id}}.\n",
    "package_to_hub(repo_id,\n",
    "               pong_policy,  # æˆ‘ä»¬æƒ³ä¿å­˜çš„æ¨¡å‹.\n",
    "               pong_hyperparameters,  # è¶…å‚æ•°.\n",
    "               eval_env,  # è¯„ä¼°ç¯å¢ƒ.\n",
    "               video_fps=30,\n",
    "               local_repo_path='hub',\n",
    "               commit_message='Push Reinforce agent to the Hub')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a65aae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## é¢å¤–çš„æŒ‘æˆ˜(å¯é€‰) ğŸ†\n",
    "æœ€å¥½çš„å­¦ä¹ æ–¹å¼å°±æ˜¯**è‡ªå·±è¿›è¡Œå°è¯•**! å¦‚ä½ æ‰€è§, å½“å‰çš„æ™ºèƒ½ä½“è¿˜æœ‰åšåˆ°æœ€å¥½. ä½œä¸ºç¬¬ä¸€ä¸ªå»ºè®®, ä½ å¯ä»¥è®­ç»ƒæ›´å¤šçš„æ—¶é—´æ­¥. ä¹Ÿå¯ä»¥å°è¯•æ‰¾åˆ°æ›´å¥½çš„å‚æ•°.\n",
    "\n",
    "åœ¨[æ’è¡Œæ¦œ](https://huggingface.co/spaces/ThomasSimonini/Lunar-Lander-Leaderboard)ä¸­, ä½ å°†æ‰¾åˆ°ä½ çš„æ™ºèƒ½ä½“çš„ä½ç½®. ä½ æƒ³è¦è·å¾—ç¬¬ä¸€å—?\n",
    "\n",
    "ä»¥ä¸‹æ˜¯ä¸€äº›å®ç°è¿™ä¸ªç›®æ ‡çš„æƒ³æ³•:\n",
    "* è®­ç»ƒæ›´å¤šçš„æ—¶é—´æ­¥\n",
    "* å°è¯•ä¸åŒçš„è¶…å‚æ•°. ä½ å¯ä»¥åœ¨ ğŸ‘‰ https://huggingface.co/models?other=reinforce çœ‹åˆ°å…¶ä»–åŒå­¦çš„è¶…å‚æ•°å®ƒä»¬\n",
    "* **å‘å¸ƒä½ è®­ç»ƒçš„æ–°æ¨¡å‹**åˆ°Hubä¸Š ğŸ”¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095e1cbe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "ç¥è´ºä½ å®Œæˆæœ¬ç« ! è¿™æ‰æ˜¯æœ€é‡è¦çš„, è¿™è¿˜æœ‰**ä¸€äº›é¢å¤–çš„ä¿¡æ¯**.\n",
    "\n",
    "å¦‚æœä½ ä»ç„¶å¯¹è¿™äº›æ„Ÿåˆ°å›°æƒ‘...è¿™æ˜¯å®Œå…¨æ­£å¸¸çš„! **è¿™å¯¹æˆ‘å’Œæ‰€æœ‰å­¦ä¹ å¼ºåŒ–å­¦ä¹ çš„äººéƒ½æ˜¯ä¸€æ ·çš„**.\n",
    "\n",
    "åœ¨ç»§ç»­å°è¯•å…¶ä»–æŒ‘æˆ˜ä¹‹å‰, **èŠ±ä¸€ç‚¹æ—¶é—´çœŸæ­£çš„æŒæ¡è¿™äº›å†…å®¹**. ç†è§£è¿™äº›å†…å®¹å¹¶æ‰“ä¸‹åŸºç¡€æ˜¯éå¸¸é‡è¦çš„.\n",
    "\n",
    "å½“ç„¶, åœ¨åç»­è¯¾ç¨‹ä¸­, æˆ‘ä»¬å°†ä¼šç»§ç»­ä½¿ç”¨å¹¶å†æ¬¡è§£é‡Šè¿™äº›å†…å®¹, ä½†**æœ€å¥½æ˜¯åœ¨å¼€å§‹ä¸‹ä¸€ç« ä¹‹å‰å®Œå…¨æŒæ¡è¿™äº›**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6357ab15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### è¿™æ˜¯ä¸“é—¨ä¸ºä½ æ‰“é€ çš„è¯¾ç¨‹ ğŸ‘·ğŸ¿â€â™€ï¸\n",
    "\n",
    "æˆ‘ä»¬å¸Œæœ›æ ¹æ®ä½ çš„åé¦ˆæé«˜å’Œæ”¹è¿›è¯¾ç¨‹. å¦‚æœä½ æœ‰ä¸€äº›å»ºè®®, è¯·æ‰“å¼€GitHubä»“åº“çš„issue: https://github.com/huggingface/deep-rl-class/issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8cb13f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ç¬¬6å•å…ƒè§! ğŸ”¥\n",
    "## ä¸æ–­å­¦ä¹ , ä¸æ–­ç²¾å½©! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}