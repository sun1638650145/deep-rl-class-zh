{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd30585b",
   "metadata": {},
   "source": [
    "# ç¬¬8å•å…ƒ: ä½¿ç”¨PyTorchç¼–å†™Proximal Policy Optimization(PPO) ğŸ¤–ï¸\n",
    "\n",
    "åœ¨æœ¬å•å…ƒä¸­, ä½ å°†å­¦ä¹ **ä½¿ç”¨PyTorchä»å¤´å¼€å§‹ç¼–å†™ä½ çš„PPOæ™ºèƒ½ä½“.**\n",
    "\n",
    "ä¸ºäº†æµ‹è¯•é²æ£’æ€§, æˆ‘ä»¬å°†åœ¨2ä¸ªä¸åŒçš„ç»å…¸ç¯å¢ƒè¿›è¡Œè®­ç»ƒ:\n",
    "\n",
    "* [CartPole-v1](https://www.gymlibrary.ml/environments/classic_control/cart_pole/?highlight=cartpole)\n",
    "* [LunarLander-v2 ğŸš€](https://www.gymlibrary.ml/environments/box2d/lunar_lander/)\n",
    "\n",
    "æˆ‘ä»¬é€šè¿‡æ·±å…¥äº†è§£PPOçš„å·¥ä½œåŸç†æ¥å®Œæˆè¯¾ç¨‹çš„åŸºç¡€éƒ¨åˆ†. åœ¨ç¬¬1å•å…ƒ, ä½ å­¦ä¹ äº†åœ¨LunarLander-v2ä¸Šè®­ç»ƒPPOæ™ºèƒ½ä½“. ä½†æ˜¯ç°åœ¨, ç¬¬8å•å…ƒ, ä½ å¯ä»¥ä»å¤´å¼€å§‹ç¼–å†™ä»£ç . è¿™çœŸæ˜¯å¤ªä¸å¯æ€è®®äº† ğŸ¤©.\n",
    "\n",
    "![cover.jpg](./assets/cover.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c085c67c",
   "metadata": {},
   "source": [
    "â¬‡ï¸ è¿™æ˜¯ä½ å°†åœ¨å‡ åˆ†é’Ÿå†…å®ç°çš„ç›®æ ‡çš„ç¤ºä¾‹([åŸå§‹è§†é¢‘1ä¸‹è½½é“¾æ¥](https://huggingface.co/sb3/ppo-CartPole-v1/resolve/main/replay.mp4), [åŸå§‹è§†é¢‘2ä¸‹è½½é“¾æ¥](https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4)). â¬‡ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d3e8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video autoplay controls><source src='./assets/replay1.mp4' type='video/mp4'></video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<video autoplay controls><source src='./assets/replay1.mp4' type='video/mp4'></video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d5948f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video autoplay controls><source src='./assets/replay2.mp4' type='video/mp4'></video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<video autoplay controls><source src='./assets/replay2.mp4' type='video/mp4'></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3924008",
   "metadata": {},
   "source": [
    "ğŸ’¡ æˆ‘ä»¬å»ºè®®ä½ ä½¿ç”¨Google Colab, å› ä¸ºæŸäº›ç¯å¢ƒåªé€‚ç”¨äºUbuntu. Google Colabçš„å…è´¹ç‰ˆæœ¬å¾ˆé€‚åˆè¿™ä¸ªæ•™ç¨‹. è®©æˆ‘ä»¬å¼€å§‹å§! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f70cfd",
   "metadata": {},
   "source": [
    "## è¿™ä»½ç¬”è®°æ¥è‡ªæ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹\n",
    "![Deep Reinforcement Learning Course.jpg](./assets/DeepReinforcementLearningCourse.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078086dd",
   "metadata": {},
   "source": [
    "åœ¨è¿™ä¸ªå…è´¹è¯¾ç¨‹ä¸­, ä½ å°†:\n",
    "\n",
    "* ğŸ“– ç ”ç©¶æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„**ç†è®ºå’Œå®è·µ.**\n",
    "* ğŸ§‘â€ğŸ’» å­¦ä¹ **ä½¿ç”¨æµè¡Œçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ åº“**, ä¾‹å¦‚Stable Baselines3, RL Baselines3 Zooå’ŒRLlib.\n",
    "* ğŸ¤–ï¸ **åœ¨ç‹¬ç‰¹çš„ç¯å¢ƒä¸­è®­ç»ƒæ™ºèƒ½ä½“.**\n",
    "\n",
    "è¿˜æœ‰æ›´å¤šçš„è¯¾ç¨‹ ğŸ“š å†…å®¹ ğŸ‘‰ https://github.com/huggingface/deep-rl-class\n",
    "\n",
    "ä¿æŒè¿›åº¦çš„æœ€ä½³æ–¹å¼æ˜¯åŠ å…¥æˆ‘ä»¬çš„DiscordæœåŠ¡å™¨ä¸ç¤¾åŒºå’Œæˆ‘ä»¬è¿›è¡Œäº¤æµ. ğŸ‘‰ğŸ» https://discord.gg/aYka4Yhff9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c04cee2",
   "metadata": {},
   "source": [
    "## å…ˆå†³æ¡ä»¶ ğŸ—\n",
    "\n",
    "åœ¨æ·±å…¥ç ”ç©¶ç¬”è®°ä¹‹å‰, ä½ éœ€è¦:\n",
    "\n",
    "ğŸ”² ğŸ“š [é˜…è¯»ç¬¬8å•å…ƒçš„README.](https://github.com/huggingface/deep-rl-class/blob/main/unit8/README.md)\n",
    "\n",
    "ğŸ”² ğŸ“š é€šè¿‡é˜…è¯»ç« èŠ‚**å­¦ä¹ Proximal Policy Optimization(PPO)** ğŸ‘‰ https://huggingface.co/blog/deep-rl-ppo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eb65e5",
   "metadata": {},
   "source": [
    "### ç¬¬0æ­¥: è®¾ç½®GPU ğŸ’ª\n",
    "\n",
    "* ä¸ºäº†**æ›´å¿«çš„è®­ç»ƒæ™ºèƒ½ä½“, æˆ‘ä»¬å°†ä½¿ç”¨GPU,** é€‰æ‹©`ä¿®æ”¹ > ç¬”è®°æœ¬è®¾ç½®`\n",
    "![image.png](./assets/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8488e0",
   "metadata": {},
   "source": [
    "* `ç¡¬ä»¶åŠ é€Ÿå™¨ > GPU`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0664be3",
   "metadata": {},
   "source": [
    "![image.png](./assets/image1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5d1cd",
   "metadata": {},
   "source": [
    "### ç¬¬1æ­¥: å®‰è£…ä¾èµ–é¡¹ ğŸ”½ å’Œ è™šæ‹Ÿå±å¹• ğŸ’»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a244064",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt install ffmpeg\n",
    "# å¦‚æœä½ ä½¿ç”¨IDE(ä¾‹å¦‚PyCharmæˆ–VS Code)å°†ä¸éœ€è¦è¿™äº›æ­¥éª¤.\n",
    "!apt install python-opengl xvfb \n",
    "!pip install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece15dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym box2d-py  # å¦‚æœä½¿ç”¨Apple M1 conda install box2d-py\n",
    "!pip install huggingface_hub\n",
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e472eb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºè™šæ‹Ÿå±å¹•.\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce758ac0",
   "metadata": {},
   "source": [
    "### ç¬¬2æ­¥: è®©æˆ‘ä»¬ä½¿ç”¨Costa Huangçš„æ•™ç¨‹ä»å¤´å¼€å§‹ç¼–å†™PPO\n",
    "* å¯¹äºPPOçš„æ ¸å¿ƒå®ç°, æˆ‘ä»¬å°†ä½¿ç”¨ä¼˜ç§€çš„[Costa Huangçš„æ•™ç¨‹](https://costa.sh/).\n",
    "* é™¤æ­¤ä¹‹å¤–, æ›´æ·±å…¥çš„äº†è§£ä½ å¯ä»¥é˜…è¯»13ä¸ªæ ¸å¿ƒå®ç°ç»†èŠ‚: https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/\n",
    "\n",
    "ğŸ‘‰ è§†é¢‘æ•™ç¨‹: https://youtu.be/MEt6rrxH8W4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d085c2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MEt6rrxH8W4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MEt6rrxH8W4\" ' \n",
    "     + 'title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; '\n",
    "     + 'clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ba4641",
   "metadata": {},
   "source": [
    "* æœ€å¥½çš„åŠæ³•æ˜¯å…ˆåœ¨ä¸‹é¢çš„å•å…ƒæ ¼ä¸­ç¼–å†™ä»£ç , è¿™æ ·å¦‚æœä½ çš„è¿›ç¨‹è¢«å…³é—­, ä¹Ÿä¸ä¼šä¸¢å¤±ä»£ç ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac0f7c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ä½ çš„ä»£ç :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b480c4ff",
   "metadata": {},
   "source": [
    "### ç¬¬3æ­¥: æ·»åŠ Hugging Faceé›†æˆ ğŸ¤—\n",
    "* ä¸ºäº†å°†æˆ‘ä»¬çš„æ¨¡å‹å‘å¸ƒåˆ°Hugging Face Hub, æˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ª`package_to_hub`å‡½æ•°.\n",
    "* æ·»åŠ æˆ‘ä»¬çš„éœ€è¦å°†æ¨¡å‹å‘å¸ƒåˆ°Hugging Face Hubçš„ä¾èµ–é¡¹."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e446ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import imageio\n",
    "import json\n",
    "import shutil\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "from huggingface_hub import HfApi, upload_folder\n",
    "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
    "from wasabi import Printer\n",
    "\n",
    "msg = Printer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a99f741",
   "metadata": {},
   "source": [
    "* åœ¨å‡½æ•°`parse_args()`ä¸­æ·»åŠ æ–°å‚æ•°æ¥å®šä¹‰æˆ‘ä»¬æƒ³è¦å‘å¸ƒæ¨¡å‹çš„`repo-id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de38bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ·»åŠ Hugging Face Hubå‚æ•°.\n",
    "parser.add_argument('--repo-id',\n",
    "                    type=str,\n",
    "                    default='ThomasSimonini/ppo-CartPole-v1',\n",
    "                    help='Hugging Face Hubä¸­æ¨¡å‹ä»“åº“çš„ID{ç”¨æˆ·å/ä»“åº“å}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad8e7dc",
   "metadata": {},
   "source": [
    "* æ¥ä¸‹æ¥, æˆ‘ä»¬æ·»åŠ å°†æ¨¡å‹å‘å¸ƒåˆ°Hugging Face Hubæ‰€éœ€çš„æ–¹æ³•\n",
    "* è¿™äº›æ–¹æ³•æœ‰:\n",
    "    * `_evalutate_agent()`: è¯„ä¼°æ™ºèƒ½ä½“.\n",
    "    * `_generate_model_card()`: ä¸ºä½ çš„æ™ºèƒ½ä½“ç”Ÿæˆæ¨¡å‹å¡.\n",
    "    * `_record_video()`: å½•åˆ¶æ™ºèƒ½ä½“çš„å›æ”¾è§†é¢‘."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b267850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def package_to_hub(repo_id,\n",
    "                   model,\n",
    "                   hyperparameters,\n",
    "                   eval_env,\n",
    "                   video_fps=30,\n",
    "                   commit_message='å‘å¸ƒå¼ºåŒ–å­¦ä¹ æ¨¡å‹åˆ°Hugging Face Hub.',\n",
    "                   token=None,\n",
    "                   logs=None):\n",
    "    \"\"\"è¯„ä¼°, ç”Ÿæˆè§†é¢‘å¹¶å°†æ¨¡å‹å‘å¸ƒåˆ°Hugging Face Hub.\n",
    "\n",
    "    æ­¤å‡½æ•°å°†æ‰§è¡Œå®Œæ•´çš„æµæ°´çº¿:\n",
    "        * è¯„ä¼°æ¨¡å‹\n",
    "        * ç”Ÿæˆæ¨¡å‹å¡\n",
    "        * ç”Ÿæˆæ™ºèƒ½ä½“çš„å›æ”¾è§†é¢‘\n",
    "        * å°†å…¨éƒ¨å†…å®¹å‘å¸ƒåˆ°Hugging Face Hub\n",
    "\n",
    "    Args:\n",
    "        repo_id: Hugging Face Hubä¸­æ¨¡å‹ä»“åº“çš„ID\n",
    "        model: è®­ç»ƒçš„æ¨¡å‹.\n",
    "        hyperparameters: è®­ç»ƒæ¨¡å‹çš„è¶…å‚æ•°.\n",
    "        eval_env: ç”¨äºè¯„ä¼°æ™ºèƒ½ä½“çš„ç¯å¢ƒ.\n",
    "        video_fps: æ¸²æŸ“å›æ”¾è§†é¢‘çš„å¸§ç‡.\n",
    "        commit_message: æäº¤çš„ä¿¡æ¯.\n",
    "        token: å‘å¸ƒæ¨¡å‹çš„Hugging Faceä»¤ç‰Œ.\n",
    "        logs: ä½ è¦ä¸Šä¼ çš„TensorBoardæ—¥å¿—çš„æœ¬åœ°ç›®å½•.\n",
    "    \"\"\"\n",
    "    msg.info('è¿™ä¸ªå‡½æ•°å°†ä¿å­˜, è¯„ä¼°, ç”Ÿæˆæ™ºèƒ½ä½“å›æ”¾è§†é¢‘, åˆ›å»ºæ¨¡å‹å¡å¹¶å°†æ¨¡å‹å‘å¸ƒåˆ°Hugging Face Hub.'\n",
    "             'æœ€å¤šå¯èƒ½éœ€è¦1åˆ†é’Ÿ. è¿™æ˜¯ä¸€é¡¹æ­£åœ¨è¿›è¡Œçš„å·¥ä½œ, å¦‚æœä½ é‡åˆ°BUG, è¯·æ‰“å¼€ä¸€ä¸ªissue.')\n",
    "\n",
    "    # ç¬¬1æ­¥: å…‹éš†æˆ–åˆ›å»ºä»“åº“.\n",
    "    repo_url = HfApi().create_repo(repo_id=repo_id,\n",
    "                                   token=token,\n",
    "                                   private=False,\n",
    "                                   exist_ok=True)\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        tmp_dir = Path(tmp_dir)\n",
    "\n",
    "        # ç¬¬2æ­¥: ä¿å­˜æ¨¡å‹.\n",
    "        torch.save(model.state_dict(), tmp_dir / 'model.pt')\n",
    "\n",
    "        # ç¬¬3æ­¥: è¯„ä¼°æ¨¡å‹å¹¶æ„å»ºJSON.\n",
    "        mean_reward, std_reward = _evaluate_agent(eval_env, 10, model)\n",
    "\n",
    "        # é¦–å…ˆ, è·å–å½“å‰æ—¶é—´.\n",
    "        eval_datetime = datetime.datetime.now()\n",
    "        eval_form_datetime = eval_datetime.isoformat()\n",
    "\n",
    "        evaluate_data = {\n",
    "            'env_id': hyperparameters.env_id,\n",
    "            'mean_reward': mean_reward,\n",
    "            'std_reward': std_reward,\n",
    "            'n_evaluation_episodes': 10,\n",
    "            'eval_datetime': eval_form_datetime\n",
    "        }\n",
    "\n",
    "        # å†™å…¥JSONæ–‡ä»¶.\n",
    "        with open(tmp_dir / 'hyperparameters.json', 'w') as outfile:\n",
    "            json.dump(evaluate_data, outfile)\n",
    "\n",
    "        # ç¬¬4æ­¥: å½•åˆ¶å›æ”¾è§†é¢‘.\n",
    "        video_path = tmp_dir / 'replay.mp4'\n",
    "        _record_video(eval_env, model, video_path, video_fps)\n",
    "\n",
    "        # ç¬¬5æ­¥: åˆ›å»ºæ¨¡å‹å¡.\n",
    "        generated_model_card, metadata = _generate_model_card('PPO',\n",
    "                                                              hyperparameters.env_id,\n",
    "                                                              mean_reward,\n",
    "                                                              std_reward,\n",
    "                                                              hyperparameters)\n",
    "        _save_model_card(tmp_dir, generated_model_card, metadata)\n",
    "\n",
    "        # ç¬¬6æ­¥: å¦‚æœéœ€è¦åˆ™æ·»åŠ æ—¥å¿—.\n",
    "        if logs:\n",
    "            _add_logdir(tmp_dir, Path(logs))\n",
    "\n",
    "        msg.info(f'æ­£åœ¨å°†ä»“åº“{repo_id}å‘å¸ƒåˆ°Hugging Face Hub...')\n",
    "\n",
    "        repo_url = upload_folder(repo_id=repo_id,\n",
    "                                 folder_path=tmp_dir,\n",
    "                                 path_in_repo='',\n",
    "                                 commit_message=commit_message,\n",
    "                                 token=token)\n",
    "\n",
    "        msg.info(f'ä½ çš„æ¨¡å‹å·²ç»å‘å¸ƒåˆ°Hugging Face Hub. ä½ å¯ä»¥ç‚¹å‡»é“¾æ¥æŸ¥çœ‹çš„ä½ çš„æ¨¡å‹: {repo_url}')\n",
    "\n",
    "    return repo_url\n",
    "\n",
    "\n",
    "def _evaluate_agent(env, n_eval_episodes, policy):\n",
    "    \"\"\"ç”¨`n_eval_episodes`è½®è¯„ä¼°æ™ºèƒ½ä½“, å¹¶è¿”å›å¥–åŠ±çš„å‡å€¼å’Œæ ‡å‡†å·®.\n",
    "\n",
    "    Args:\n",
    "        env: è¯„ä¼°ç¯å¢ƒ.\n",
    "        n_eval_episodes: æµ‹è¯•çš„æ€»è½®æ•°.\n",
    "        policy: å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“.\n",
    "\n",
    "    Returns:\n",
    "        å¥–åŠ±çš„å‡å€¼å’Œæ ‡å‡†å·®.\n",
    "    \"\"\"\n",
    "    episode_rewards = []\n",
    "\n",
    "    for episode in range(n_eval_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        total_rewards_ep = 0\n",
    "\n",
    "        while done is False:\n",
    "            state = torch.Tensor(state)\n",
    "            action, _, _, _ = policy.get_action_and_value(state)\n",
    "            new_state, reward, done, info = env.step(action.numpy())\n",
    "            total_rewards_ep += reward\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "            state = new_state\n",
    "        episode_rewards.append(total_rewards_ep)\n",
    "\n",
    "    mean_reward = np.mean(episode_rewards)\n",
    "    std_reward = np.std(episode_rewards)\n",
    "\n",
    "    return mean_reward, std_reward\n",
    "\n",
    "\n",
    "def _record_video(env, policy, out_directory, fps=30):\n",
    "    images = []\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    img = env.render(mode='rgb_array')\n",
    "    images.append(img)\n",
    "\n",
    "    while not done:\n",
    "        state = torch.Tensor(state)\n",
    "        # åœ¨ç»™å®šçŠ¶æ€ä¸‹, é‡‡å–å…·æœ‰æœ€å¤§æœŸæœ›å¥–åŠ±çš„åŠ¨ä½œ(ç´¢å¼•).\n",
    "        action, _, _, _ = policy.get_action_and_value(state)\n",
    "        state, reward, done, info = env.step(action)  # æˆ‘ä»¬ç›´æ¥ä½¿ç”¨next_state = stateæ¥è®°å½•é¡ºåº(recording logic).\n",
    "        img = env.render(mode='rgb_array')\n",
    "        images.append(img)\n",
    "\n",
    "    imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)\n",
    "\n",
    "\n",
    "def _generate_model_card(model_name, env_id, mean_reward, std_reward, hyperparameters):\n",
    "    \"\"\"ä¸ºHugging Face Hubç”Ÿæˆæ¨¡å‹å¡.\n",
    "\n",
    "    Args:\n",
    "        model_name: æ¨¡å‹çš„åç§°.\n",
    "        env_id: ç¯å¢ƒçš„åç§°.\n",
    "        mean_reward: å¥–ç½šçš„å‡å€¼.\n",
    "        std_reward: å¥–ç½šçš„æ ‡å‡†å·®.\n",
    "        hyperparameters: è®­ç»ƒæ¨¡å‹çš„è¶…å‚æ•°.\n",
    "    \"\"\"\n",
    "    # ç¬¬1æ­¥: é€‰æ‹©å…ƒæ•°æ®.\n",
    "    metadata = _generate_metadata(model_name, env_id, mean_reward, std_reward)\n",
    "\n",
    "    # å°†è¶…å‚æ•°å‘½åç©ºé—´è½¬æ¢ä¸ºå­—ç¬¦ä¸².\n",
    "    converted_dict = vars(hyperparameters)\n",
    "    converted_str = str(converted_dict)\n",
    "    converted_str = converted_str.split(', ')\n",
    "    converted_str = '\\n'.join(converted_str)\n",
    "\n",
    "    # ç¬¬2æ­¥: ç”Ÿæˆæ¨¡å‹å¡.\n",
    "    model_card = f'''\n",
    "    # ä½¿ç”¨PPOæ™ºèƒ½ä½“æ¥ç© {env_id}\n",
    "    \n",
    "    è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨PPOè®­ç»ƒæœ‰ç´ çš„æ¨¡å‹ç© {env_id}.\n",
    "    è¦å­¦ä¹ ç¼–å†™ä½ è‡ªå·±çš„PPOæ™ºèƒ½ä½“å¹¶è®­ç»ƒå®ƒ, \n",
    "    è¯·æŸ¥é˜…æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ç¬¬8å•å…ƒ: https://github.com/huggingface/deep-rl-class/tree/main/unit8\n",
    "    \n",
    "    # è¶…å‚æ•°\n",
    "    ```python\n",
    "    {converted_str}\n",
    "    ```\n",
    "    '''\n",
    "\n",
    "    return model_card, metadata\n",
    "\n",
    "\n",
    "def _generate_metadata(model_name, env_id, mean_reward, std_reward):\n",
    "    \"\"\"å®šä¹‰æ¨¡å‹å¡çš„å…ƒæ•°æ®.\n",
    "\n",
    "    Args:\n",
    "        model_name: æ¨¡å‹çš„åç§°.\n",
    "        env_id: ç¯å¢ƒçš„åç§°.\n",
    "        mean_reward: å¥–ç½šçš„å‡å€¼.\n",
    "        std_reward: å¥–ç½šçš„æ ‡å‡†å·®.\n",
    "    \"\"\"\n",
    "    metadata = {\n",
    "        'tag': [\n",
    "            env_id,\n",
    "            'ppo',\n",
    "            'deep-reinforcement-learning',\n",
    "            'reinforcement-learning',\n",
    "            'custom-implementation',\n",
    "            'deep-rl-class'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # æ·»åŠ è¯„ä¼°.\n",
    "    eval = metadata_eval_result(model_pretty_name=model_name,\n",
    "                                task_pretty_name='reinforcement-learning',\n",
    "                                task_id='reinforcement-learning',\n",
    "                                metrics_pretty_name='mean_reward',\n",
    "                                metrics_id='mean_reward',\n",
    "                                metrics_value=f'{mean_reward:.2f} +/- {std_reward:.2f}',\n",
    "                                dataset_pretty_name=env_id,\n",
    "                                dataset_id=env_id)\n",
    "\n",
    "    # åˆå¹¶æ‰€æœ‰çš„å­—å…¸.\n",
    "    metadata = {**metadata, **eval}\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def _save_model_card(local_path, generated_model_card, metadata):\n",
    "    \"\"\"ä¿å­˜æ¨¡å‹å¡åˆ°ä»“åº“.\n",
    "\n",
    "    Args:\n",
    "        local_path: ä»“åº“çš„åœ°å€.\n",
    "        generated_model_card: é€šè¿‡`_generate_model_card()`ç”Ÿæˆçš„æ¨¡å‹å¡.\n",
    "        metadata: å…ƒæ•°æ®.\n",
    "    \"\"\"\n",
    "    readme_path = local_path / 'README.md'\n",
    "\n",
    "    if readme_path.exists():\n",
    "        with readme_path.open('r', encoding='utf8') as f:\n",
    "            readme = f.read()\n",
    "    else:\n",
    "        readme = generated_model_card\n",
    "\n",
    "    with readme_path.open('w', encoding='utf-8') as f:\n",
    "        f.write(readme)\n",
    "\n",
    "    # ä¿å­˜æˆ‘ä»¬çš„è¯„ä¼°ä¿¡æ¯åˆ°READMEçš„å…ƒæ•°æ®.\n",
    "    metadata_save(readme_path, metadata)\n",
    "\n",
    "\n",
    "def _add_logdir(local_path: Path,\n",
    "                logdir: Path):\n",
    "    \"\"\"æ·»åŠ æ—¥å¿—åˆ°ä»“åº“.\n",
    "\n",
    "    Args:\n",
    "        local_path: ä»“åº“çš„åœ°å€.\n",
    "        logdir: æ—¥å¿—çš„åœ°å€.\n",
    "    \"\"\"\n",
    "    if logdir.exists() and logdir.is_dir():\n",
    "        # æ·»åŠ æ—¥å¿—åˆ°ä»“åº“ä¸‹, æ–°åœ°å€å«`logs`\n",
    "        repo_logdir = local_path / 'logs'\n",
    "\n",
    "        # å¦‚æœå½“å‰çš„æ—¥å¿—ç›®å½•å­˜åœ¨, å°±åˆ é™¤.\n",
    "        if repo_logdir.exists():\n",
    "            shutil.rmtree(repo_logdir)\n",
    "\n",
    "        # å¤åˆ¶æ—¥å¿—åˆ°ä»“åº“çš„æ—¥å¿—ä¸­.\n",
    "        shutil.copytree(logdir, repo_logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018dca8d",
   "metadata": {},
   "source": [
    "* æœ€å, æˆ‘ä»¬åœ¨PPOè®­ç»ƒå®Œåè°ƒç”¨è¿™ä¸ªå‡½æ•°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºä¸€ä¸ªè¯„ä¼°ç¯å¢ƒ.\n",
    "eval_env = gym.make(args.env_id)\n",
    "\n",
    "package_to_hub(repo_id=args.repo_id,\n",
    "               model=agent,  # æˆ‘ä»¬æƒ³è¦ä¿å­˜çš„æ¨¡å‹.\n",
    "               hyperparameters=args,\n",
    "               eval_env=gym.make(args.env_id),\n",
    "               logs=f'runs/{runs_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39b3d4",
   "metadata": {},
   "source": [
    "* è¿™æ˜¯æœ€ç»ˆçš„`ppo.py`æ–‡ä»¶çš„æ ·å­."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061cf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–‡æ¡£å’Œå®éªŒç»“æœå¯ä»¥åœ¨ https://docs.cleanrl.dev/rl-algorithms/ppo/#ppopy æ‰¾åˆ°.\n",
    "import argparse\n",
    "import datetime\n",
    "import imageio\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "from distutils.util import strtobool\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from huggingface_hub.hf_api import HfApi\n",
    "from huggingface_hub.hf_api import upload_folder\n",
    "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
    "from wasabi import Printer\n",
    "\n",
    "msg = Printer()\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--exp-name', type=str, default=os.path.basename(__file__).rstrip('.py'), help='å®éªŒçš„åç§°')\n",
    "    parser.add_argument('--seed', type=int, default=1, help='å®éªŒçš„éšæœºç§å­')\n",
    "    parser.add_argument('--torch-deterministic',\n",
    "                        type=lambda x: bool(strtobool(x)),\n",
    "                        default=True,\n",
    "                        nargs='?',\n",
    "                        const=True,\n",
    "                        help='å‡å°‘ç®—æ³•çš„éšæœºæ€§, å¦‚æœåˆ‡æ¢, `torch.backends.cudnn.deterministic=False`')\n",
    "    parser.add_argument('--cuda',\n",
    "                        type=lambda x: bool(strtobool(x)),\n",
    "                        default=True,\n",
    "                        nargs='?',\n",
    "                        const=True,\n",
    "                        help='é»˜è®¤æƒ…å†µä¸‹å°†å¯ç”¨CUDA')\n",
    "    parser.add_argument('--track',\n",
    "                        type=lambda x: bool(strtobool(x)),\n",
    "                        default=False,\n",
    "                        nargs='?',\n",
    "                        const=True,\n",
    "                        help='è¯¥å®éªŒå°†å¯¹æƒé‡å’Œåå·®è¿›è¡Œè¿½è¸ª')\n",
    "    parser.add_argument('--wandb-project-name', type=str, default='cleanRL', help='wanDbé¡¹ç›®çš„åç§°')\n",
    "    parser.add_argument('--wandb-entity', type=str, default=None, help='wanDbé¡¹ç›®çš„å®ä½“')\n",
    "    parser.add_argument('--capture-video',\n",
    "                        type=lambda x: bool(strtobool(x)),\n",
    "                        default=False,\n",
    "                        nargs='?',\n",
    "                        const=True,\n",
    "                        help='æ˜¯å¦ä¿å­˜æ™ºèƒ½ä½“çš„å›æ”¾è§†é¢‘(æŸ¥çœ‹`videos`æ–‡ä»¶å¤¹)')\n",
    "\n",
    "    # ç®—æ³•å‚æ•°.\n",
    "    parser.add_argument('--env-id', type=str, default='CartPole-v1', help='ç¯å¢ƒçš„åç§°')\n",
    "    parser.add_argument('--total-timesteps', type=int, default=50000, help='å®éªŒçš„æ€»æ—¶é—´æ­¥')\n",
    "    parser.add_argument('--learning-rate', type=float, default=2.5e-4, help='ä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡')\n",
    "    parser.add_argument('--num-envs', type=int, default=4, help='å¹¶è¡Œçš„ç¯å¢ƒæ•°é‡')\n",
    "    parser.add_argument('--num-steps', type=int, default=128, help='æ¯ä¸ªç¯å¢ƒä¸­ç­–ç•¥çš„æ¯è½®æœ€å¤§æ­¥æ•°')\n",
    "    parser.add_argument('--anneal-lr',\n",
    "                        type=lambda x: bool(strtobool(x)),\n",
    "                        default=True,\n",
    "                        nargs='?',\n",
    "                        const=True,\n",
    "                        help='ç­–ç•¥å’Œä»·å€¼ç½‘ç»œçš„å­¦ä¹ ç‡é€€ç«')\n",
    "    parser.add_argument('--gae',\n",
    "                        type=lambda x: bool(strtobool(x)),\n",
    "                        default=True,\n",
    "                        nargs='?',\n",
    "                        const=True,\n",
    "                        help='ä½¿ç”¨å¹¿ä¹‰ä¼˜åŠ¿ä¼°è®¡å™¨è¿›è¡Œä¼˜åŠ¿è®¡ç®—')\n",
    "    parser.add_argument('--gamma', type=float, default=0.99, help='æŠ˜æ‰£ç³»æ•°')\n",
    "    parser.add_argument('--gae-lambda', type=float, default=0.95, help='å¹¿ä¹‰ä¼˜åŠ¿ä¼°è®¡å™¨çš„åå·®ä¸æ–¹å·®æƒè¡¡å› å­')\n",
    "\n",
    "    # æ·»åŠ Hugging Faceå‚æ•°.\n",
    "    parser.add_argument('--repo-id',\n",
    "                        type=str,\n",
    "                        default='ThomasSimonini/ppo-CartPole-v1',\n",
    "                        help='Hugging Face Hubä¸­æ¨¡å‹ä»“åº“çš„ID{ç”¨æˆ·å/ä»“åº“å}')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.batch_size = int(args.num_envs * args.num_steps)\n",
    "    args.minibatch_size = int(args.batch_size // args.num_minibatches)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def package_to_hub(repo_id,\n",
    "                   model,\n",
    "                   hyperparameters,\n",
    "                   eval_env,\n",
    "                   video_fps=30,\n",
    "                   commit_message='å‘å¸ƒå¼ºåŒ–å­¦ä¹ æ¨¡å‹åˆ°Hugging Face Hub.',\n",
    "                   token=None,\n",
    "                   logs=None):\n",
    "    \"\"\"è¯„ä¼°, ç”Ÿæˆè§†é¢‘å¹¶å°†æ¨¡å‹å‘å¸ƒåˆ°Hugging Face Hub.\n",
    "\n",
    "    æ­¤å‡½æ•°å°†æ‰§è¡Œå®Œæ•´çš„æµæ°´çº¿:\n",
    "        * è¯„ä¼°æ¨¡å‹\n",
    "        * ç”Ÿæˆæ¨¡å‹å¡\n",
    "        * ç”Ÿæˆæ™ºèƒ½ä½“çš„å›æ”¾è§†é¢‘\n",
    "        * å°†å…¨éƒ¨å†…å®¹å‘å¸ƒåˆ°Hugging Face Hub\n",
    "\n",
    "    Args:\n",
    "        repo_id: Hugging Face Hubä¸­æ¨¡å‹ä»“åº“çš„ID\n",
    "        model: è®­ç»ƒçš„æ¨¡å‹.\n",
    "        hyperparameters: è®­ç»ƒæ¨¡å‹çš„è¶…å‚æ•°.\n",
    "        eval_env: ç”¨äºè¯„ä¼°æ™ºèƒ½ä½“çš„ç¯å¢ƒ.\n",
    "        video_fps: æ¸²æŸ“å›æ”¾è§†é¢‘çš„å¸§ç‡.\n",
    "        commit_message: æäº¤çš„ä¿¡æ¯.\n",
    "        token: å‘å¸ƒæ¨¡å‹çš„Hugging Faceä»¤ç‰Œ.\n",
    "        logs: ä½ è¦ä¸Šä¼ çš„TensorBoardæ—¥å¿—çš„æœ¬åœ°ç›®å½•.\n",
    "    \"\"\"\n",
    "    msg.info('è¿™ä¸ªå‡½æ•°å°†ä¿å­˜, è¯„ä¼°, ç”Ÿæˆæ™ºèƒ½ä½“å›æ”¾è§†é¢‘, åˆ›å»ºæ¨¡å‹å¡å¹¶å°†æ¨¡å‹å‘å¸ƒåˆ°Hugging Face Hub.'\n",
    "             'æœ€å¤šå¯èƒ½éœ€è¦1åˆ†é’Ÿ. è¿™æ˜¯ä¸€é¡¹æ­£åœ¨è¿›è¡Œçš„å·¥ä½œ, å¦‚æœä½ é‡åˆ°BUG, è¯·æ‰“å¼€ä¸€ä¸ªissue.')\n",
    "\n",
    "    # ç¬¬1æ­¥: å…‹éš†æˆ–åˆ›å»ºä»“åº“.\n",
    "    repo_url = HfApi().create_repo(repo_id=repo_id,\n",
    "                                   token=token,\n",
    "                                   private=False,\n",
    "                                   exist_ok=True)\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        tmp_dir = Path(tmp_dir)\n",
    "\n",
    "        # ç¬¬2æ­¥: ä¿å­˜æ¨¡å‹.\n",
    "        torch.save(model.state_dict(), tmp_dir / 'model.pt')\n",
    "\n",
    "        # ç¬¬3æ­¥: è¯„ä¼°æ¨¡å‹å¹¶æ„å»ºJSON.\n",
    "        mean_reward, std_reward = _evaluate_agent(eval_env, 10, model)\n",
    "\n",
    "        # é¦–å…ˆ, è·å–å½“å‰æ—¶é—´.\n",
    "        eval_datetime = datetime.datetime.now()\n",
    "        eval_form_datetime = eval_datetime.isoformat()\n",
    "\n",
    "        evaluate_data = {\n",
    "            'env_id': hyperparameters.env_id,\n",
    "            'mean_reward': mean_reward,\n",
    "            'std_reward': std_reward,\n",
    "            'n_evaluation_episodes': 10,\n",
    "            'eval_datetime': eval_form_datetime\n",
    "        }\n",
    "\n",
    "        # å†™å…¥JSONæ–‡ä»¶.\n",
    "        with open(tmp_dir / 'hyperparameters.json', 'w') as outfile:\n",
    "            json.dump(evaluate_data, outfile)\n",
    "\n",
    "        # ç¬¬4æ­¥: å½•åˆ¶å›æ”¾è§†é¢‘.\n",
    "        video_path = tmp_dir / 'replay.mp4'\n",
    "        _record_video(eval_env, model, video_path, video_fps)\n",
    "\n",
    "        # ç¬¬5æ­¥: åˆ›å»ºæ¨¡å‹å¡.\n",
    "        generated_model_card, metadata = _generate_model_card('PPO',\n",
    "                                                              hyperparameters.env_id,\n",
    "                                                              mean_reward,\n",
    "                                                              std_reward,\n",
    "                                                              hyperparameters)\n",
    "        _save_model_card(tmp_dir, generated_model_card, metadata)\n",
    "\n",
    "        # ç¬¬6æ­¥: å¦‚æœéœ€è¦åˆ™æ·»åŠ æ—¥å¿—.\n",
    "        if logs:\n",
    "            _add_logdir(tmp_dir, Path(logs))\n",
    "\n",
    "        msg.info(f'æ­£åœ¨å°†ä»“åº“{repo_id}å‘å¸ƒåˆ°Hugging Face Hub...')\n",
    "\n",
    "        repo_url = upload_folder(repo_id=repo_id,\n",
    "                                 folder_path=tmp_dir,\n",
    "                                 path_in_repo='',\n",
    "                                 commit_message=commit_message,\n",
    "                                 token=token)\n",
    "\n",
    "        msg.info(f'ä½ çš„æ¨¡å‹å·²ç»å‘å¸ƒåˆ°Hugging Face Hub. ä½ å¯ä»¥ç‚¹å‡»é“¾æ¥æŸ¥çœ‹çš„ä½ çš„æ¨¡å‹: {repo_url}')\n",
    "\n",
    "    return repo_url\n",
    "\n",
    "\n",
    "def _evaluate_agent(env, n_eval_episodes, policy):\n",
    "    \"\"\"ç”¨`n_eval_episodes`è½®è¯„ä¼°æ™ºèƒ½ä½“, å¹¶è¿”å›å¥–åŠ±çš„å‡å€¼å’Œæ ‡å‡†å·®.\n",
    "\n",
    "    Args:\n",
    "        env: è¯„ä¼°ç¯å¢ƒ.\n",
    "        n_eval_episodes: æµ‹è¯•çš„æ€»è½®æ•°.\n",
    "        policy: å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“.\n",
    "\n",
    "    Returns:\n",
    "        å¥–åŠ±çš„å‡å€¼å’Œæ ‡å‡†å·®.\n",
    "    \"\"\"\n",
    "    episode_rewards = []\n",
    "\n",
    "    for episode in range(n_eval_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        total_rewards_ep = 0\n",
    "\n",
    "        while done is False:\n",
    "            state = torch.Tensor(state)\n",
    "            action, _, _, _ = policy.get_action_and_value(state)\n",
    "            new_state, reward, done, info = env.step(action.numpy())\n",
    "            total_rewards_ep += reward\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "            state = new_state\n",
    "        episode_rewards.append(total_rewards_ep)\n",
    "\n",
    "    mean_reward = np.mean(episode_rewards)\n",
    "    std_reward = np.std(episode_rewards)\n",
    "\n",
    "    return mean_reward, std_reward\n",
    "\n",
    "\n",
    "def _record_video(env, policy, out_directory, fps=30):\n",
    "    images = []\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    img = env.render(mode='rgb_array')\n",
    "    images.append(img)\n",
    "\n",
    "    while not done:\n",
    "        state = torch.Tensor(state)\n",
    "        # åœ¨ç»™å®šçŠ¶æ€ä¸‹, é‡‡å–å…·æœ‰æœ€å¤§æœŸæœ›å¥–åŠ±çš„åŠ¨ä½œ(ç´¢å¼•).\n",
    "        action, _, _, _ = policy.get_action_and_value(state)\n",
    "        state, reward, done, info = env.step(action)  # æˆ‘ä»¬ç›´æ¥ä½¿ç”¨next_state = stateæ¥è®°å½•é¡ºåº(recording logic).\n",
    "        img = env.render(mode='rgb_array')\n",
    "        images.append(img)\n",
    "\n",
    "    imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)\n",
    "\n",
    "\n",
    "def _generate_model_card(model_name, env_id, mean_reward, std_reward, hyperparameters):\n",
    "    \"\"\"ä¸ºHugging Face Hubç”Ÿæˆæ¨¡å‹å¡.\n",
    "\n",
    "    Args:\n",
    "        model_name: æ¨¡å‹çš„åç§°.\n",
    "        env_id: ç¯å¢ƒçš„åç§°.\n",
    "        mean_reward: å¥–ç½šçš„å‡å€¼.\n",
    "        std_reward: å¥–ç½šçš„æ ‡å‡†å·®.\n",
    "        hyperparameters: è®­ç»ƒæ¨¡å‹çš„è¶…å‚æ•°.\n",
    "    \"\"\"\n",
    "    # ç¬¬1æ­¥: é€‰æ‹©å…ƒæ•°æ®.\n",
    "    metadata = _generate_metadata(model_name, env_id, mean_reward, std_reward)\n",
    "\n",
    "    # å°†è¶…å‚æ•°å‘½åç©ºé—´è½¬æ¢ä¸ºå­—ç¬¦ä¸².\n",
    "    converted_dict = vars(hyperparameters)\n",
    "    converted_str = str(converted_dict)\n",
    "    converted_str = converted_str.split(', ')\n",
    "    converted_str = '\\n'.join(converted_str)\n",
    "\n",
    "    # ç¬¬2æ­¥: ç”Ÿæˆæ¨¡å‹å¡.\n",
    "    model_card = f'''\n",
    "    # ä½¿ç”¨PPOæ™ºèƒ½ä½“æ¥ç© {env_id}\n",
    "    \n",
    "    è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨PPOè®­ç»ƒæœ‰ç´ çš„æ¨¡å‹ç© {env_id}.\n",
    "    è¦å­¦ä¹ ç¼–å†™ä½ è‡ªå·±çš„PPOæ™ºèƒ½ä½“å¹¶è®­ç»ƒå®ƒ, \n",
    "    è¯·æŸ¥é˜…æ·±åº¦å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹ç¬¬8å•å…ƒ: https://github.com/huggingface/deep-rl-class/tree/main/unit8\n",
    "    \n",
    "    # è¶…å‚æ•°\n",
    "    ```python\n",
    "    {converted_str}\n",
    "    ```\n",
    "    '''\n",
    "\n",
    "    return model_card, metadata\n",
    "\n",
    "\n",
    "def _generate_metadata(model_name, env_id, mean_reward, std_reward):\n",
    "    \"\"\"å®šä¹‰æ¨¡å‹å¡çš„å…ƒæ•°æ®.\n",
    "\n",
    "    Args:\n",
    "        model_name: æ¨¡å‹çš„åç§°.\n",
    "        env_id: ç¯å¢ƒçš„åç§°.\n",
    "        mean_reward: å¥–ç½šçš„å‡å€¼.\n",
    "        std_reward: å¥–ç½šçš„æ ‡å‡†å·®.\n",
    "    \"\"\"\n",
    "    metadata = {\n",
    "        'tag': [\n",
    "            env_id,\n",
    "            'ppo',\n",
    "            'deep-reinforcement-learning',\n",
    "            'reinforcement-learning',\n",
    "            'custom-implementation',\n",
    "            'deep-rl-class'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # æ·»åŠ è¯„ä¼°.\n",
    "    eval = metadata_eval_result(model_pretty_name=model_name,\n",
    "                                task_pretty_name='reinforcement-learning',\n",
    "                                task_id='reinforcement-learning',\n",
    "                                metrics_pretty_name='mean_reward',\n",
    "                                metrics_id='mean_reward',\n",
    "                                metrics_value=f'{mean_reward:.2f} +/- {std_reward:.2f}',\n",
    "                                dataset_pretty_name=env_id,\n",
    "                                dataset_id=env_id)\n",
    "\n",
    "    # åˆå¹¶æ‰€æœ‰çš„å­—å…¸.\n",
    "    metadata = {**metadata, **eval}\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def _save_model_card(local_path, generated_model_card, metadata):\n",
    "    \"\"\"ä¿å­˜æ¨¡å‹å¡åˆ°ä»“åº“.\n",
    "\n",
    "    Args:\n",
    "        local_path: ä»“åº“çš„åœ°å€.\n",
    "        generated_model_card: é€šè¿‡`_generate_model_card()`ç”Ÿæˆçš„æ¨¡å‹å¡.\n",
    "        metadata: å…ƒæ•°æ®.\n",
    "    \"\"\"\n",
    "    readme_path = local_path / 'README.md'\n",
    "\n",
    "    if readme_path.exists():\n",
    "        with readme_path.open('r', encoding='utf8') as f:\n",
    "            readme = f.read()\n",
    "    else:\n",
    "        readme = generated_model_card\n",
    "\n",
    "    with readme_path.open('w', encoding='utf-8') as f:\n",
    "        f.write(readme)\n",
    "\n",
    "    # ä¿å­˜æˆ‘ä»¬çš„è¯„ä¼°ä¿¡æ¯åˆ°READMEçš„å…ƒæ•°æ®.\n",
    "    metadata_save(readme_path, metadata)\n",
    "\n",
    "\n",
    "def _add_logdir(local_path: Path,\n",
    "                logdir: Path):\n",
    "    \"\"\"æ·»åŠ æ—¥å¿—åˆ°ä»“åº“.\n",
    "\n",
    "    Args:\n",
    "        local_path: ä»“åº“çš„åœ°å€.\n",
    "        logdir: æ—¥å¿—çš„åœ°å€.\n",
    "    \"\"\"\n",
    "    if logdir.exists() and logdir.is_dir():\n",
    "        # æ·»åŠ æ—¥å¿—åˆ°ä»“åº“ä¸‹, æ–°åœ°å€å«`logs`\n",
    "        repo_logdir = local_path / 'logs'\n",
    "\n",
    "        # å¦‚æœå½“å‰çš„æ—¥å¿—ç›®å½•å­˜åœ¨, å°±åˆ é™¤.\n",
    "        if repo_logdir.exists():\n",
    "            shutil.rmtree(repo_logdir)\n",
    "\n",
    "        # å¤åˆ¶æ—¥å¿—åˆ°ä»“åº“çš„æ—¥å¿—ä¸­.\n",
    "        shutil.copytree(logdir, repo_logdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
