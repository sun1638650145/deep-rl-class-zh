{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 第1单元: 训练你的第一个深度强化学习智能体🚀\n",
    "在这份笔记中, 你将训练你的第一个着陆器智能体**正确登陆月球🌕并将其分享到社区, 并记得实验不同的配置**\n",
    "\n",
    "❓如果你有任何问题, 请在discord的#study-group-unit1频道发帖 👉 https://discord.gg/aYka4Yhff9\n",
    "\n",
    "🎮 环境: [LunarLander-v2](https://www.gymlibrary.ml/environments/box2d/lunar_lander/)\n",
    "\n",
    "📚 强化学习库: [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/)\n",
    "\n",
    "⬇️ 这是你将在几分钟内实现的目标的示例([原始视频下载链接](https://huggingface.co/ThomasSimonini/ppo-LunarLander-v2/resolve/main/replay.mp4)). ⬇️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video autoplay controls><source src=\"./assets/replay.mp4\" type=\"video/mp4\"></video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<video autoplay controls><source src=\"./assets/replay.mp4\" type=\"video/mp4\"></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 这份笔记的目标🏆\n",
    "在这份笔记学习结束后, 你将:\n",
    "* 能够使用环境库**Gym**.\n",
    "* 能够使用深度强化学习库**Stable-Baselines3**.\n",
    "* 能够通过精彩的回放和得分🔥**发布你训练的智能体到Hugging Face Hub**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 这份笔记来自深度强化学习课程\n",
    "![深度强化学习课程.jpg](./assets/DeepReinforcementLearningCourse.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "在这个免费课程中, 你将:\n",
    "* 📖 研究深度强化学习的**理论和实践**.\n",
    "* 🧑‍💻 学习**使用流行的深度强化学习库**, 例如Stable Baselines3, RL Baselines3 Zoo和RLlib.\n",
    "* 🤖️ 在独特的环境中训练**智能体**.\n",
    "\n",
    "还有更多的课程 📚 内容 👉 https://github.com/huggingface/deep-rl-class\n",
    "\n",
    "保持进度的最佳方式是加入我们的Discord服务器与社区和我们进行交流. 👉🏻 https://discord.gg/aYka4Yhff9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 先决条件 🏗\n",
    "在深入研究笔记之前, 你需要:\n",
    "\n",
    "🔲 📚 [阅读第1单元的README.](https://github.com/huggingface/deep-rl-class/blob/main/unit1/README.md)\n",
    "\n",
    "🔲 📚 先学习**强化学习基础**(蒙特卡洛MC, 时序差分TD和奖励假设...) 👉 https://huggingface.co/blog/deep-rl-intro\n",
    "\n",
    "🔲 📢 注册[我们的Discord服务器](https://discord.gg/aYka4Yhff9)**并在#introduce-yourself频道介绍自己** 🥳\n",
    "\n",
    "🔲 🐕 你是Discord新手吗? 请查看我们的**discord 101以获得最佳实践** 👉 https://github.com/huggingface/deep-rl-class/blob/main/DISCORD.Md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 一个深度强化学习的小回顾📚\n",
    "![image.png](./assets/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "有**两种**方法可以找到你的最优策略:\n",
    "* 通过**训练直接训练你的策略**: 基于策略的方法.\n",
    "* 通过**训练预期回报的价值函数**, 智能体将在每个状态下使用我们的函数定义我们的策略: 基于价值的方法."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* 最后, 我们谈到深度强化学习是因为**我们引入了深度神经网络去评估采取的动作(基于策略)或估算状态的价值(基于价值), 所以得名“深度”**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 让我们训练一个深度强化学习着陆器智能体来正确的着陆月球🌕并且上传到 Hugging Face Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 第0步: 设置GPU 💪\n",
    "* 为了**更快的训练智能体, 我们将使用GPU**, 选择`修改 > 笔记本设置`\n",
    "![image.png](./assets/image1.png)\n",
    "* `硬件加速器 > GPU`\n",
    "![image.png](./assets/image2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "在笔记中, 我们需要生成一个回放视频. 因此在Colab(或你本地的jupyter)中, **我们需要一个虚拟屏幕能渲染环境**(记录视频帧).\n",
    "\n",
    "下面的单元格将安装虚拟屏幕库并创建和运行虚拟屏幕. 🖥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The operation couldn’t be completed. Unable to locate a Java Runtime.\r\n",
      "Please visit http://www.java.com for information on installing Java.\r\n",
      "\r\n",
      "The operation couldn’t be completed. Unable to locate a Java Runtime.\r\n",
      "Please visit http://www.java.com for information on installing Java.\r\n",
      "\r\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\r\n",
      "Requirement already satisfied: pyvirtualdisplay in /Users/sunruiqi/miniforge3/envs/RL/lib/python3.9/site-packages (3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!apt install gitlfs ffmpeg\n",
    "# 如果你使用IDE(例如PyCharm或VS Code)将不需要这些步骤.\n",
    "!apt install python-opengl xvfb \n",
    "!pip install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Xvfb'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# 创建虚拟屏幕.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyvirtualdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Display\n\u001B[0;32m----> 4\u001B[0m virtual_display \u001B[38;5;241m=\u001B[39m \u001B[43mDisplay\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvisible\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1400\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m900\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m virtual_display\u001B[38;5;241m.\u001B[39mstart()\n",
      "File \u001B[0;32m~/miniforge3/envs/RL/lib/python3.9/site-packages/pyvirtualdisplay/display.py:54\u001B[0m, in \u001B[0;36mDisplay.__init__\u001B[0;34m(self, backend, visible, size, color_depth, bgcolor, use_xauth, retries, extra_args, manage_global_env, **kwargs)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcls\u001B[39m:\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munknown backend: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend)\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolor_depth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolor_depth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbgcolor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbgcolor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_xauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_xauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# check_startup=check_startup,\u001B[39;49;00m\n\u001B[1;32m     61\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextra_args\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmanage_global_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanage_global_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/RL/lib/python3.9/site-packages/pyvirtualdisplay/xvfb.py:44\u001B[0m, in \u001B[0;36mXvfbDisplay.__init__\u001B[0;34m(self, size, color_depth, bgcolor, use_xauth, fbdir, dpi, retries, extra_args, manage_global_env)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fbdir \u001B[38;5;241m=\u001B[39m fbdir\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dpi \u001B[38;5;241m=\u001B[39m dpi\n\u001B[0;32m---> 44\u001B[0m \u001B[43mAbstractDisplay\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[43mPROGRAM\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_xauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_xauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[43mextra_args\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmanage_global_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanage_global_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/RL/lib/python3.9/site-packages/pyvirtualdisplay/abstractdisplay.py:85\u001B[0m, in \u001B[0;36mAbstractDisplay.__init__\u001B[0;34m(self, program, use_xauth, retries, extra_args, manage_global_env)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pipe_wfd \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retries_current \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 85\u001B[0m helptext \u001B[38;5;241m=\u001B[39m \u001B[43mget_helptext\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprogram\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_displayfd \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-displayfd\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m helptext\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_displayfd:\n",
      "File \u001B[0;32m~/miniforge3/envs/RL/lib/python3.9/site-packages/pyvirtualdisplay/util.py:13\u001B[0m, in \u001B[0;36mget_helptext\u001B[0;34m(program)\u001B[0m\n\u001B[1;32m      6\u001B[0m cmd \u001B[38;5;241m=\u001B[39m [program, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-help\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# py3.7+\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# p = subprocess.run(cmd, capture_output=True)\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# stderr = p.stderr\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# py3.6 also\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m p \u001B[38;5;241m=\u001B[39m \u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcmd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstderr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshell\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m _, stderr \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mcommunicate()\n\u001B[1;32m     21\u001B[0m helptext \u001B[38;5;241m=\u001B[39m stderr\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniforge3/envs/RL/lib/python3.9/subprocess.py:951\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001B[0m\n\u001B[1;32m    947\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_mode:\n\u001B[1;32m    948\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mTextIOWrapper(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr,\n\u001B[1;32m    949\u001B[0m                     encoding\u001B[38;5;241m=\u001B[39mencoding, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m--> 951\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreexec_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    952\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mpass_fds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcwd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    953\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstartupinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreationflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshell\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    954\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mp2cread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp2cwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    955\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mc2pread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc2pwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    956\u001B[0m \u001B[43m                        \u001B[49m\u001B[43merrread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    957\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mrestore_signals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    958\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mgid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mumask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    959\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstart_new_session\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    960\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m    961\u001B[0m     \u001B[38;5;66;03m# Cleanup if the child failed starting.\u001B[39;00m\n\u001B[1;32m    962\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m, (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstdin, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstdout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr)):\n",
      "File \u001B[0;32m~/miniforge3/envs/RL/lib/python3.9/subprocess.py:1821\u001B[0m, in \u001B[0;36mPopen._execute_child\u001B[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001B[0m\n\u001B[1;32m   1819\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errno_num \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1820\u001B[0m         err_msg \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mstrerror(errno_num)\n\u001B[0;32m-> 1821\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001B[1;32m   1822\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m child_exception_type(err_msg)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'Xvfb'"
     ]
    }
   ],
   "source": [
    "# 创建虚拟屏幕.\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 第1步: 安装依赖项 🔽\n",
    "第一步是安装多个依赖项:\n",
    "* `gym`: 包含LunarLander-v2环境🌛\n",
    "* `stable-baselines3`: 深度强化学习库.\n",
    "* `huggingface_sb3`: Stable-baselines3的插件, 用于从Hugging Face Hub 🤗 上下载或者上传模型."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install gym pygame box2d-py  # 如果使用Apple M1 conda install box2d-py\n",
    "!pip install stable-baselines3\n",
    "!pip install huggingface_sb3\n",
    "!pip install pyglet  # 如果你使用IDE, 则不需要这些步骤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 第2步: 导入包 📦\n",
    "我们导入的另一个库是 huggingface_hub, **它能从Hub上下载或者上传预训练模型**.\n",
    "\n",
    "Hugging Face Hub 🤗 是一个任何人都可以分享和探索模型和数据集的地方. 它有版本控制, 评估, 可视化和其他功能, 可以允许你简单地与他人协作.\n",
    "\n",
    "你可以在这看到全部可用的深度强化学习模型. 👉 https://huggingface.co/models?pipeline_tag=reinforcement-learning&sort=downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from huggingface_sb3 import load_from_hub, package_to_hub, push_to_hub\n",
    "from huggingface_hub import notebook_login  # 需要登陆Hugging Face账户才能将模型上传到Hub.\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 第3步: 了解什么是Gym以及它是如何工作的? 🤖️\n",
    "🏋️ 这个包含我们环境的库叫做Gym. 你将在**深度强化学习中使用很多Gym的环境**. \n",
    "\n",
    "Gym库提供了两个东西:\n",
    "* 允许你**创建强化学习环境**的接口.\n",
    "* **一组环境**(gym-control, atrai, box2D...).\n",
    "\n",
    "让我们看一个例子, 但首先让我们记住什么是强化学习循环."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image.png](./assets/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "在每一步:\n",
    "* 我们的智能体从**环境**接收**状态S0** -- 我们接收我们游戏(环境)的第一帧画面.\n",
    "* 基于**状态S0**, 智能体采取**行动A0** -- 我们的智能体将向右移动.\n",
    "* 从环境产生中**新状态S1** -- 新的一帧画面.\n",
    "* 环境给智能体一些**奖罚R1** -- 我们没有死(奖励+1).\n",
    "\n",
    "在Gym中:\n",
    "\n",
    "1⃣️ 我们使用`gym.make()`创建环境\n",
    "\n",
    "2⃣️ 我们使用`observation = env.reset()`重置环境到初始状态\n",
    "\n",
    "对于每一步:\n",
    "\n",
    "3⃣️ 我们使用模型获取一个动作(在我们的例子中, 我们获取一个随机的动作)\n",
    "\n",
    "4⃣️ 我们使用`env.step(action)`在环境中执行这个动作, 然后得到:\n",
    "* `obsevation`: 新状态(st+1)\n",
    "* `reward`: 我们执行动作后得到的奖罚\n",
    "* `done`: 提示这局游戏是否结束\n",
    "* `info`: 额外信息的字典(取决于具体的环境).\n",
    "\n",
    "如果这局游戏结束:\n",
    "* 我们再次使用`observation = env.reset()`重置环境到初始状态\n",
    "\n",
    "**让我们看看这个例子!** 确保读懂代码."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "# 首先, 我们创建LunarLander-v2的环境.\n",
    "env = gym.make('LunarLander-v2')  \n",
    "\n",
    "# 重置环境到初始状态.\n",
    "observation = env.reset()\n",
    "\n",
    "for _ in range(20):\n",
    "    # 如果你使用IDE, 可以取消渲染环境的注释.\n",
    "    # env.render()\n",
    "    # 获取一个随机动作.\n",
    "    action = env.action_space.sample()  \n",
    "    print('动作: ', action)\n",
    "    \n",
    "    # 执行动作, 获取新状态, 奖罚, 这局游戏是否结束和额外信息.\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    \n",
    "    # 如果这局游戏结束(这个例子中结束的标志是着陆, 坠毁或超时).\n",
    "    if done:\n",
    "        # 重置环境到初始状态.\n",
    "        print('环境被重置.')\n",
    "        observation = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 第4步: 创建LunarLander环境🌛并且了解它如何工作\n",
    "#### [环境 🎮](https://www.gymlibrary.ml/environments/box2d/lunar_lander/)\n",
    "在第一个教程中, 我们将训练一个[登月着陆器]((https://www.gymlibrary.ml/environments/box2d/lunar_lander/)智能体, 它将正确的登陆月球. 为此, 智能体需要**学习去调整它的速度和位置(水平, 垂直和角度)来正确着陆**.\n",
    "\n",
    "---\n",
    "💡 当你开始使用一个环境的好习惯是查看文档.\n",
    "\n",
    "👉 https://www.gymlibrary.ml/environments/box2d/lunar_lander/\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "让我们一起看看环境是什么样的:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 我们使用 gym.make('<环境的名称>') 创建环境.\n",
    "env = gym.make('LunarLander-v2')\n",
    "env.reset()\n",
    "print('_' * 5 + '可观察的环境' + '_' * 5)\n",
    "print()\n",
    "print('可观察的环境向量的形状', env.observation_space.shape)\n",
    "print('随机采样环境', env.observation_space.sample())  # 获得一个随机的可观察环境空间."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "我们看到`可观察的环境空间的形状 (8,)`, 这指出可观察空间是一个大小为8的向量, 每个值是着陆器的不同信息:\n",
    "* 着陆器坐标(x)\n",
    "* 着陆器坐标(y)\n",
    "* 水平速度(x)\n",
    "* 垂直速度(y)\n",
    "* 角度\n",
    "* 角速度\n",
    "* 左侧起落架是否着陆\n",
    "* 右侧起落架是否着陆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('_' * 5 + '动作空间' + '_' * 5)\n",
    "print()\n",
    "print('动作的总数', env.action_space.n)\n",
    "print('随机动作', env.action_space.sample())  # 获得一个随机的动作."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "动作空间(智能体可用的可能动作集)是有4个可用动作的离散值 🎮:\n",
    "* 不行动,\n",
    "* 启动左方向的引擎,\n",
    "* 启动主引擎,\n",
    "* 启动右方向的引擎.\n",
    "\n",
    "奖励函数(在每个时间步给予的奖励)💰:\n",
    "* 从屏幕顶部移动到着陆台, 零速度是100~140分.\n",
    "* 启动主引擎每帧画面 -0.3分.\n",
    "* 每侧起落架着地+10分.\n",
    "* 如果着陆器坠毁(额外-100分)或停止(+100分), 则本轮游戏结束.\n",
    "* 如果你的智能体得到200分, 你的任务就结束了."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 向量化环境\n",
    "* 我们创建一个由16个环境组成的向量化环境(堆叠多个独立环境在一个环境的方法), 这样**我们将有更多样化的体验在训练过程**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 创建环境.\n",
    "env = make_vec_env('LunarLander-v2', n_envs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 第5步: 创建一个模型 🤖️\n",
    "* 现在我们研究了我们的环境并且理解了我们的问题: **通过控制左, 右方向和主引擎能够正确的将着陆器降落到着陆台上**. 让我们构建一个算法来解决这个问题. 🚀\n",
    "* 为此, 我们将使用我们的第一个深度强化学习库, [Stable Baselines3(SB3)](https://stable-baselines3.readthedocs.io/en/master/).\n",
    "* SB3是**一组PyTorch强化学习算法的可靠实现集合**.\n",
    "---\n",
    "💡 使用新的库的好习惯是先阅读文档: https://stable-baselines3.readthedocs.io/en/master/ 然后尝试一些教程.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image.png](./assets/image3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "为了解决这个问题, 我们将使用SB3 **PPO**. [PPO(又名近端策略优化(Proximal Policy Optimization))是一种在本课程中你将学到的最先进的深度强化学习算法之一.](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#example%5D)\n",
    "\n",
    "PPO是以下各项的组合:\n",
    "* 基于价值的强化学习方法: 通过学习一个动作-价值函数来告诉我们在**给定的状态和动作下的最有价值的动作**.\n",
    "* 基于策略的强化学习方法: 通过学习一个策略来给我们**动作的概率分布**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Stable-Baselines3 易于设置:\n",
    "\n",
    "1⃣️ 你**创建一个环境**(我们的例子中已经在上面完成)\n",
    "\n",
    "2⃣️ 你**定义一个你想使用的模型并实例化它**`model = PPO('MlpPolicy')`\n",
    "\n",
    "3⃣️ 你通过`model.learn()`**训练智能体**, 并定义训练的时间步\n",
    "\n",
    "```\n",
    "# 创建环境\n",
    "env = gym.make('LunarLander-v2')\n",
    "\n",
    "# 实例化智能体\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "# 训练智能体\n",
    "model.learn(total_timesteps=int(2e5))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: 定义MlpPolicy PPO架构\n",
    "# 我们使用多层感知机(MlpPolicy)是因为输入是一个向量, \n",
    "# 如果我们输入是帧, 那我们将使用CnnPolicy.\n",
    "model = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 答案\n",
    "# 我们添加了一些参数来更快的训练\n",
    "model = PPO(policy='MlpPolicy',\n",
    "            env=env,\n",
    "            n_steps=1024,\n",
    "            batch_size=64,\n",
    "            n_epochs=4,\n",
    "            gamma=0.99,\n",
    "            gae_lambda=0.98,\n",
    "            ent_coef=0.01,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 第6步: 训练PPO智能体 🏃\n",
    "* 让我们训练智能体 500000 步, 不要忘记使用Colab的GPU. 这大概需要10分钟, 但如果你仅想尝试一下, 你可使用更少的时间步.\n",
    "* 在训练期间, ☕️好好休息一下吧 🤗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: 训练500000步\n",
    "\n",
    "# TODO: 指定模型的文件名并保存模型.\n",
    "model_name = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 答案\n",
    "# 训练500000步\n",
    "model.learn(total_timesteps=500000)\n",
    "# 保存模型\n",
    "model_name = 'ppo-LunarLander-v2'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 第7步: 评估智能体 📈\n",
    "* 现在我们的登月着陆器智能体已经训练好了🚀, 我们需要**检查它的性能**.\n",
    "* Stable-Baselines3 提供了一个方法`evaluate_policy`来进行评估.\n",
    "* 要填写哪些部分, 你需要[查看文档](https://stable-baselines3.readthedocs.io/en/master/guide/examples.html#basic-usage-training-saving-loading)\n",
    "* 下一步, 我们将了解**如何自动评估和分享你的智能体到排行榜竞争**, 现在让我们自己做\n",
    "\n",
    "💡 当你评估你的智能体时, 你不应该使用训练环境, 而是创建一个评估环境."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: 评估智能体\n",
    "# 创建一个新的评估环境\n",
    "eval_env = \n",
    "\n",
    "# 使用10个评估周期和确定性动作评估模型\n",
    "mean_reward, std_reward = \n",
    "\n",
    "# 打印结果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_env = gym.make('LunarLander-v2')\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
    "print(f'mean_reward={mean_reward:.2f} +/- {std_reward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* 就我而言, 在训练1百万步后我得到的平均奖励是`200.20 +/- 20.80`, 这意味着我们的登月着陆器智能体已经准备好登陆月球了.🌛🥳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 第8步(不涉及核心内容, 可选): 发布我们训练好的模型到 Hub 上 🔥\n",
    "现在我们看到经过训练之后得到了很棒的结果, 我们可以通过一行代码发布我们训练的模型到hub🤗上.\n",
    "\n",
    "📚 库文档 👉 https://github.com/huggingface/huggingface_sb3/tree/main#hugging-face--x-stable-baselines3-v20\n",
    "\n",
    "这有一个模型卡的例子(使用Space Invaders):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![ModelCard.gif](./assets/ModelCard.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "通过使用`package_to_hub`, **你可以评估, 记录回放视频, 生成智能体的模型卡并把它发布到hub**.\n",
    "\n",
    "---\n",
    "package_to_hub 函数\n",
    "---\n",
    "\n",
    "看这边:\n",
    "* 你可以**展示我们的作品** 🔥\n",
    "* 你可以**可视化智能体的活动** 👀\n",
    "* 你可以**与社区分享其他人也可以使用的智能体** 💾\n",
    "* 你可以**访问排行榜🏆以查看你的智能体和你同学的智能体相比如何** 👉 https://huggingface.co/spaces/ThomasSimonini/Lunar-Lander-Leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "为了能分享你的模型到社区, 有以下三个步骤需要做:\n",
    "\n",
    "1⃣️ (如果没有完成)创建一个Hugging Face账户 ➡ https://huggingface.co/join\n",
    "\n",
    "2⃣️ 登陆账户, 然后你需要保存一个Hugging Face的身份验证令牌(token).\n",
    "\n",
    "* 创建一个新的具有**写入规则**的令牌(https://huggingface.co/settings/tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![image.png](./assets/image4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* 复制令牌\n",
    "* 运行下面的脚本并输入令牌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "notebook_login()\n",
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "如果你使用IDE, 也可在终端中使用以下命令:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3⃣️ 我们现在准备好使用`package_to_hub()`发布我们训练的智能体到🤗 hub 🔥."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "让我们填写`package_to_hub`函数:\n",
    "* `model`: 我们训练的模型.\n",
    "* `model_name`: 我们在`model.save()`中定义的模型的名称.\n",
    "* `model_architectrue`: 我们使用的模型架构: 在我们的例子中是PPO.\n",
    "* `env_id`: 环境的名称, 在我们的例子中是`LunarLander-v2`.\n",
    "* `eval_env`: 定义一个评估环境.\n",
    "* `repo_id`: 将创建/更新的Hugging Face Hub仓库的名称(repo_id={你的用户名/仓库名}).\n",
    "\n",
    "💡 **一个好的名字是{用户名}/{模型架构}-{环境名称}**\n",
    "\n",
    "* `commit_message`: 提交时的信息."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "from huggingface_sb3 import package_to_hub\n",
    "\n",
    "# 创建评估环境.\n",
    "eval_env = DummyVecEnv([lambda: gym.make(env_id)])\n",
    "\n",
    "# TODO: 填写环境的名称.\n",
    "env_id = ''\n",
    "\n",
    "# TODO: 填写我们使用的模型结构.\n",
    "model_architecture = ''\n",
    "\n",
    "# TODO: 填写仓库id.\n",
    "# `repo_id`是Hugging Face Hub中模型存储库的id\n",
    "# (repo_id = {organization}/{repo_name} 例子 ThomasSimonini/ppo-LunarLander-v2)\n",
    "repo_id = ''\n",
    "\n",
    "# TODO: 填写提交信息.\n",
    "commit_message = ''\n",
    "\n",
    "# 在将仓库推送到hub之前, 需要保存评估模型, 生成模型卡以及录制智能体的回放视频.\n",
    "package_to_hub(model=model,  # 我们训练的模型.\n",
    "               model_name=model_name,  # 我们训练模型的名称.\n",
    "               model_architecture=model_architecture,  # 我们使用的模型架构: 在我们的例子中是PPO.\n",
    "               env_id=env_id,  # 环境的名称.\n",
    "               eval_env=eval_env,  # 评估环境.\n",
    "               repo_id=repo_id,  # Hugging Face Hub仓库的名称(repo_id={你的用户名/仓库名} 例子 ThomasSimonini/ppo-LunarLander-v2).\n",
    "               commit_message=commit_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "from huggingface_sb3 import package_to_hub\n",
    "\n",
    "# 创建评估环境.\n",
    "eval_env = DummyVecEnv([lambda: gym.make(env_id)])\n",
    "\n",
    "# 填写环境的名称.\n",
    "env_id = 'LunarLander-v2'\n",
    "\n",
    "# 填写我们使用的模型结构.\n",
    "model_architecture = 'PPO'\n",
    "\n",
    "# 填写仓库id.\n",
    "# 请更改成你自己的id!\n",
    "repo_id = 'ThomasSimonini/TEST2ppo-LunarLander-v2'\n",
    "\n",
    "# 填写提交信息.\n",
    "commit_message = 'Upload PPO LunarLander-v2 trained agent.'\n",
    "\n",
    "package_to_hub(model=model,  # 我们训练的模型.\n",
    "               model_name=model_name,  # 我们训练模型的名称.\n",
    "               model_architecture=model_architecture,\n",
    "               env_id=env_id,\n",
    "               eval_env=eval_env,\n",
    "               repo_id=repo_id,\n",
    "               commit_message=commit_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "恭喜🥳你刚刚训练并上传了你的第一个深度强化学习智能体. 上面的脚步应该显示了模型仓库的链接, 例如: https://huggingface.co/osanseviero/test_sb3. 当你访问这个链接时, 你可以:\n",
    "* 在右侧你可以看到智能体的回放视频.\n",
    "* 点击\"Files and versions\"以查看仓库中的全部文件.\n",
    "* 点击\"Use in stable-baselines3\"以获取如何加载模型的代码.\n",
    "* 得到描述模型的模型卡(文件`README.md`).\n",
    "\n",
    "在底层, Hub使用基于git的仓库(即使你不知道什么是git也不用担心), 这意味着你可以在实验和提高你的智能体以后更新新版本的模型.\n",
    "\n",
    "使用排行榜🏆比较你和同学的LunarLander-v2结果 👉 https://huggingface.co/spaces/ThomasSimonini/Lunar-Lander-Leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 额外的挑战(可选) 🏆\n",
    "最好的学习方式就是**自己进行尝试**! 如你所见, 当前的智能体还有做到最好. 作为第一个建议, 你可以训练更多的时间步. 比如1000000步, 我们可以看到更好的结果!\n",
    "\n",
    "在[排行榜](https://huggingface.co/spaces/ThomasSimonini/Lunar-Lander-Leaderboard)中, 你将找到你的智能体的位置. 你想要获得第一吗?\n",
    "\n",
    "以下是一些实现这个目标的想法:\n",
    "* 训练更多的时间步\n",
    "* 尝试不同的`PPO`超参数. 你可以在 https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#parameters 看到它们\n",
    "* 翻阅[Stable-Baselines3的文档](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html)并尝试其他的模型, 比如DQN.\n",
    "* **发布你训练的新模型**到Hub上 🔥\n",
    "\n",
    "在[排行榜](https://huggingface.co/spaces/ThomasSimonini/Lunar-Lander-Leaderboard)上**比较你和同学的LunarLander-v2结果** 🏆 👉 https://huggingface.co/spaces/ThomasSimonini/Lunar-Lander-Leaderboard\n",
    "\n",
    "登月对你来说太无聊了? 尝试**其他环境**, 为什么不试试CartPole-v1, MountainCar-v0 或者 CarRacing-v0? [使用gym文档](https://www.gymlibrary.ml/)查询它们如何工作. 玩得开心🎉."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "祝贺你完成本章! 这才是最重要的, 这还有**一些额外的信息**.\n",
    "\n",
    "如果你仍然对这些感到困惑...这是完全正常的! **这对我和所有学习强化学习的人都是一样的**.\n",
    "\n",
    "在继续尝试其他挑战之前, **花一点时间真正的掌握这些内容**. 理解这些内容并打下基础是非常重要的.\n",
    "\n",
    "当然, 在后续课程中, 我们将会继续使用并再次解释这些内容, 但**最好是在开始下一章之前完全掌握这些**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 这是专门为你打造的课程 👷🏿‍♀️\n",
    "\n",
    "我们希望根据你的反馈提高和改进课程. 如果你有一些建议, 请打开GitHub仓库的issue: https://github.com/huggingface/deep-rl-class/issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "第二单元见! 🔥\n",
    "## 不断学习, 不断精彩! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}