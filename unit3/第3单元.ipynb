{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ff25c16",
   "metadata": {},
   "source": [
    "# 第3单元: 使用RL Baselines3 Zoo的深度Q-Learning玩雅达利的游戏 👾\n",
    "\n",
    "在这份笔记中, 你将使用[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)训练一个玩太空侵略者的**深度Q-Learning智能体,** 这是一个基于[Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/)的训练框架, 它提供了用于训练, 评估智能体, 微调超参数, 可视化结果和录制回放视频的脚本.\n",
    "\n",
    "❓如果你有任何问题, 请在discord的#study-group-unit3频道发帖 👉 https://discord.gg/aYka4Yhff9\n",
    "\n",
    "🎮 环境:\n",
    "\n",
    "* SpacesInvadersNoFrameskip-v4\n",
    "📚 强化学习库: [Stable-Baselines3](https://stable-baselines3.readthedocs.io/en/master/)\n",
    "\n",
    "⬇️ 这是**你将在几分钟内实现的目标**的示例([原始视频下载链接](https://huggingface.co/ThomasSimonini/ppo-SpaceInvadersNoFrameskip-v4/resolve/main/replay.mp4)). ⬇️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd761c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<video autoplay controls><source src='./assets/replay.mp4' type='video/mp4'></video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac083f",
   "metadata": {},
   "source": [
    "## 这份笔记的目标🏆\n",
    "\n",
    "在这份笔记学习结束后, 你将:\n",
    "\n",
    "* 能够深入了解**RL Baselines3 Zoo的工作原理.**\n",
    "* 能够通过精彩的回放和得分🔥**发布你训练的智能体到Hugging Face Hub.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8c9b27",
   "metadata": {},
   "source": [
    "## 这份笔记来自深度强化学习课程\n",
    "![Deep Reinforcement Learning Course.jpg](./assets/DeepReinforcementLearningCourse.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd81e71",
   "metadata": {},
   "source": [
    "在这个免费课程中, 你将:\n",
    "\n",
    "* 📖 研究深度强化学习的**理论和实践.**\n",
    "* 🧑‍💻 学习**使用流行的深度强化学习库**, 例如Stable Baselines3, RL Baselines3 Zoo和RLlib.\n",
    "* 🤖️ **在独特的环境中训练智能体.**\n",
    "\n",
    "还有更多的课程 📚 内容 👉 https://github.com/huggingface/deep-rl-class\n",
    "\n",
    "保持进度的最佳方式是加入我们的Discord服务器与社区和我们进行交流. 👉🏻 https://discord.gg/aYka4Yhff9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab90a5c1",
   "metadata": {},
   "source": [
    "## 先决条件 🏗\n",
    "\n",
    "在深入研究笔记之前, 你需要:\n",
    "\n",
    "🔲 📚 [阅读第3单元的README.](https://github.com/huggingface/deep-rl-class/blob/main/unit3/README.md)\n",
    "\n",
    "🔲 📚 [阅读**深度Q-Learning**](https://huggingface.co/blog/deep-rl-dqn)\n",
    "\n",
    "🔲 📢 注册[我们的Discord服务器](https://discord.gg/aYka4Yhff9)并**在#introduce-yourself频道介绍自己 🥳**\n",
    "\n",
    "🔲 🐕 你是Discord新手吗? 请查看我们**的discord 101以获得最佳实践** 👉 https://github.com/huggingface/deep-rl-class/blob/main/DISCORD.Md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dd0af2",
   "metadata": {},
   "source": [
    "# 让我们训练一个玩雅达利的太空侵略者 👾 的深度Q-Learning智能体并将其上传到Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6844928c",
   "metadata": {},
   "source": [
    "### 第0步: 设置GPU 💪\n",
    "\n",
    "* 为了**更快的训练智能体, 我们将使用GPU,** 选择`修改 > 笔记本设置`\n",
    "![image.png](./assets/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d9973b",
   "metadata": {},
   "source": [
    "* `硬件加速器 > GPU`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f926bb",
   "metadata": {},
   "source": [
    "![image.png](./assets/image1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684e292",
   "metadata": {},
   "source": [
    "### 第0+步: 设置一个虚拟屏幕🖥\n",
    "\n",
    "在笔记中, 我们需要生成一个回放视频. 因此在Colab(或你本地的jupyter)中, **我们需要一个虚拟屏幕能渲染环境**(记录视频帧).\n",
    "\n",
    "下面的单元格将安装虚拟屏幕库并创建和运行虚拟屏幕. 🖥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c200d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt install gitlfs ffmpeg\n",
    "# 如果你使用IDE(例如PyCharm或VS Code)将不需要这些步骤.\n",
    "!apt install python-opengl xvfb \n",
    "!pip install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建虚拟屏幕.\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4e650",
   "metadata": {},
   "source": [
    "### 第1步: 克隆RL-Baselines3 Zoo的仓库 📚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358749d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/DLR-RM/rl-baselines3-zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149b2112",
   "metadata": {},
   "source": [
    "### 第2步: 安装依赖项 🔽\n",
    "\n",
    "第一步是安装RL-Baselines3 Zoo需要的依赖项(这可能需要5分钟 ⏲️):\n",
    "\n",
    "同时我们也需要安装:\n",
    "* `huggingface_sb3`: Stable-baselines3的插件, 用于从Hugging Face Hub 🤗 上下载或者上传模型."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./rl-baselines3-zoo/\n",
    "!pip install -r requirements.txt\n",
    "!pip install huggingface_sb3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b72a9d",
   "metadata": {},
   "source": [
    "### 第3步: 训练我们的深度Q-Learning智能体来玩太空侵略者 👾\n",
    "使用RL-Baselines3-Zoo训练智能体, 我们仅需要做2件事:\n",
    "1. 我们在`rl-baselines3-zoo/hyperparams/dqn.yml`中定义超参数."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e2691",
   "metadata": {},
   "source": [
    "![image.png](./assets/image2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e4d21",
   "metadata": {},
   "source": [
    "这里我们可以看到:\n",
    "* 我们使用雅达利修饰器对输入预处理(裁切帧, 灰度图, 4帧堆叠)\n",
    "* 我们使用`CnnPolicy`, 因为我们使用卷积层处理图像帧\n",
    "* 我们训练它10M个`n_time_steps`\n",
    "* 缓冲区大小(经验回放)是100000\n",
    "\n",
    "💡 我的建议是将**训练的时间步减少到1M步,** 如果你想训练10M步, 你应该在你本地的服务器上运行(来避免Colab超时), 只需要点击: `文件>下载`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e9ea3f",
   "metadata": {},
   "source": [
    "你可以查阅文档来了解每个超参数的作用: https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html?highlight=deep%20q%20learning#parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6581767a",
   "metadata": {},
   "source": [
    "2. 我们运行`train.py`并将模型保存到`logs`文件夹 📁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe63342",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "--algo __________ \\\n",
    "--env SpaceInvadersNoFrameskip-v4 \\\n",
    "-f __________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f728b2e",
   "metadata": {},
   "source": [
    "#### 答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a40b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "--algo dqn \\\n",
    "--env SpaceInvadersNoFrameskip-v4 \\\n",
    "-f ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e89fc4",
   "metadata": {},
   "source": [
    "### 第4步: 评估我们的智能体 👀\n",
    "* `RL-Baselines3-Zoo`提供了`enjoy.py`来评估我们的智能体.\n",
    "* 让我们评估它5000个时间步 🔥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc6b058",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python enjoy.py \\\n",
    "--algo dqn \\\n",
    "--env SpaceInvadersNoFrameskip-v4 \\\n",
    "--no-render \\\n",
    "--n-timesteps __________ \\\n",
    "--folder ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ca1d4",
   "metadata": {},
   "source": [
    "#### 答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a87e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python enjoy.py \\\n",
    "--algo dqn \\\n",
    "--env SpaceInvadersNoFrameskip-v4 \\\n",
    "--no-render \\\n",
    "--n-timesteps 5000 \\\n",
    "--folder ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18fe6e9",
   "metadata": {},
   "source": [
    "### 第5步(不涉及核心内容, 可选): 发布我们训练好的模型到Hub上 🚀\n",
    "现在我们看到经过训练之后得到了很棒的结果, 我们可以通过一行代码发布我们训练的模型到hub 🤗 上."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa6676",
   "metadata": {},
   "source": [
    "![ModelCard.gif](./assets/ModelCard.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e85437",
   "metadata": {},
   "source": [
    "通过使用`utils.push_to_pub.py`, **你可以评估, 记录回放视频, 生成智能体的模型卡并把它发布到hub.**\n",
    "\n",
    "看这边:\n",
    "\n",
    "* 你可以**展示我们的作品** 🔥\n",
    "* 你可以**可视化智能体的活动** 👀\n",
    "* 你可以**与社区分享其他人也可以使用的智能体** 💾\n",
    "* 你可以**访问排行榜🏆以查看你的智能体和你同学的智能体相比如何** 👉 https://huggingface.co/spaces/chrisjay/Deep-Reinforcement-Learning-Leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b0ef84",
   "metadata": {},
   "source": [
    "为了能分享你的模型到社区, 有以下三个步骤需要做:\n",
    "\n",
    "1⃣️ (如果没有完成)创建一个Hugging Face账户 ➡ https://huggingface.co/join\n",
    "\n",
    "2⃣️ 登陆账户, 然后你需要保存一个Hugging Face的身份验证令牌(token).\n",
    "\n",
    "* 创建一个新的具有**写入规则**的令牌(https://huggingface.co/settings/tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff156ba",
   "metadata": {},
   "source": [
    "![image.png](./assets/image3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28723133",
   "metadata": {},
   "source": [
    "* 复制令牌\n",
    "* 运行下面脚本并输入令牌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844b13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()\n",
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdded738",
   "metadata": {},
   "source": [
    "如果你使用IDE, 也可在终端中使用以下命令:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9024bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b855e8c0",
   "metadata": {},
   "source": [
    "3⃣️ 我们现在准备好发布我们训练的智能体到🤗 hub 🔥."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24878ca3",
   "metadata": {},
   "source": [
    "让我们运行push_to_hub.py文件将我们训练的智能体上传到Hub.\n",
    "\n",
    "`--repo-name`: 仓库的名称.\n",
    "\n",
    "`--orga`: 你的Hugging Face用户名."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa382c8b",
   "metadata": {},
   "source": [
    "![image.png](./assets/image4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f97c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m utils.push_to_hub \\\n",
    "--algo dqn \\\n",
    "--env SpaceInvadersNoFrameskip-v4 \\\n",
    "--repo-name __________ \\\n",
    "--orga __________ \\\n",
    "-f ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a125a9c",
   "metadata": {},
   "source": [
    "#### 答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54123163",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m utils.push_to_hub \\\n",
    "--algo dqn \\\n",
    "--env SpaceInvadersNoFrameskip-v4 \\\n",
    "--repo-name dqn-SpaceInvadersNoFrameskip-v4 \\\n",
    "--orga TomasSimonini \\ # 请更改成你自己的id!\n",
    "-f ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce26ee3f",
   "metadata": {},
   "source": [
    "恭喜🥳你刚刚使用RL-Baselines3 Zoo训练并上传了你的第一个深度Q-Learning智能体. 上面的脚步应该显示了模型仓库的链接, 例如: https://huggingface.co/ThomasSimonini/dqn-SpaceInvadersNoFrameskip-v4. 当你访问这个链接时, 你可以:\n",
    "\n",
    "* 在右侧你可以看到智能体的回放视频.\n",
    "* 点击\"Files and versions\"以查看仓库中的全部文件.\n",
    "* 点击\"Use in stable-baselines3\"以获取如何加载模型的代码.\n",
    "* 得到描述模型和模型使用的超参数的模型卡(文件`README.md`).\n",
    "\n",
    "在底层, Hub使用基于git的仓库(即使你不知道什么是git也不用担心), 这意味着你可以在实验和提高你的智能体以后更新新版本的模型.\n",
    "\n",
    "使用排行榜🏆比较你和同学的SpaceInvadersNoFrameskip-v4结果 👉 https://huggingface.co/spaces/chrisjay/Deep-Reinforcement-Learning-Leaderboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
